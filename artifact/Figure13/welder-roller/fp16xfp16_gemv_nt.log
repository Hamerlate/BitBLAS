{<Node, roller_matmul>: {'block': [1, 4], 'thread': [1, 4], 'rstep': [2048], 'reduce_thread': [32], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.08790016174316406
{<Node, roller_matmul>: {'block': [1, 8], 'thread': [1, 8], 'rstep': [1024], 'reduce_thread': [16], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.09336580336093903
{<Node, roller_matmul>: {'block': [1, 2], 'thread': [1, 2], 'rstep': [4096], 'reduce_thread': [64], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.0868438333272934
{<Node, roller_matmul>: {'block': [1, 32], 'thread': [1, 32], 'rstep': [256], 'reduce_thread': [4], 'block_order': <NoRasterization>, 'vectorize': {'A': 2, 'B': 8}}}
0.19845296442508698
{<Node, roller_matmul>: {'block': [1, 16], 'thread': [1, 16], 'rstep': [512], 'reduce_thread': [8], 'block_order': <NoRasterization>, 'vectorize': {'A': 4, 'B': 8}}}
0.11323264241218567
{<Node, roller_matmul>: {'block': [1, 1], 'thread': [1, 1], 'rstep': [4096], 'reduce_thread': [128], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.08464178442955017
{<Node, roller_matmul>: {'block': [1, 64], 'thread': [1, 64], 'rstep': [128], 'reduce_thread': [2], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
0.46544212102890015
{<Node, roller_matmul>: {'block': [1, 128], 'thread': [1, 128], 'rstep': [64], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
0.31616151332855225
{<Node, roller_matmul>: {'block': [1, 256], 'thread': [1, 128], 'rstep': [64], 'block_order': <NoRasterization>, 'step': [1, 2], 'vectorize': {'B': 8}}}
0.5772117376327515
best code __global__ void __launch_bounds__(128) Fused(half* __restrict__ A, half* __restrict__ B, half* __restrict__ C) {
  
  half normal_reduce_temp0[1];
  __shared__ half A_shared[4096];
  __shared__ half B_shared[4096];
  __shared__ half red_buf0[128];
  normal_reduce_temp0[0] = __float2half_rn(0.000000e+00f);
  for (int k_outer = 0; k_outer < 2; ++k_outer) {
    __syncthreads();
    *(uint4*)(A_shared + (((int)threadIdx.x) * 8)) = *(uint4*)(A + ((k_outer * 4096) + (((int)threadIdx.x) * 8)));
    *(uint4*)(A_shared + ((((int)threadIdx.x) * 8) + 1024)) = *(uint4*)(A + (((k_outer * 4096) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(A_shared + ((((int)threadIdx.x) * 8) + 2048)) = *(uint4*)(A + (((k_outer * 4096) + (((int)threadIdx.x) * 8)) + 2048));
    *(uint4*)(A_shared + ((((int)threadIdx.x) * 8) + 3072)) = *(uint4*)(A + (((k_outer * 4096) + (((int)threadIdx.x) * 8)) + 3072));
    *(uint4*)(B_shared + (((int)threadIdx.x) * 8)) = *(uint4*)(B + (((((int)blockIdx.x) * 8192) + (k_outer * 4096)) + (((int)threadIdx.x) * 8)));
    *(uint4*)(B_shared + ((((int)threadIdx.x) * 8) + 1024)) = *(uint4*)(B + ((((((int)blockIdx.x) * 8192) + (k_outer * 4096)) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(B_shared + ((((int)threadIdx.x) * 8) + 2048)) = *(uint4*)(B + ((((((int)blockIdx.x) * 8192) + (k_outer * 4096)) + (((int)threadIdx.x) * 8)) + 2048));
    *(uint4*)(B_shared + ((((int)threadIdx.x) * 8) + 3072)) = *(uint4*)(B + ((((((int)blockIdx.x) * 8192) + (k_outer * 4096)) + (((int)threadIdx.x) * 8)) + 3072));
    __syncthreads();
    for (int k_inner_outer = 0; k_inner_outer < 32; ++k_inner_outer) {
      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + (A_shared[((k_inner_outer * 128) + ((int)threadIdx.x))] * B_shared[((k_inner_outer * 128) + ((int)threadIdx.x))]));
    }
  }
  __syncthreads();
  ((volatile half*)red_buf0)[((int)threadIdx.x)] = normal_reduce_temp0[0];
  __syncthreads();
  if (((int)threadIdx.x) < 64) {
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 64)]));
  }
  __syncthreads();
  if (((int)threadIdx.x) < 32) {
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 32)]));
  }
  __syncthreads();
  if (((int)threadIdx.x) < 16) {
    half w_16_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 16)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_16_0;
    half w_8_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 8)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_8_0;
    half w_4_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 4)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_4_0;
    half w_2_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 2)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_2_0;
    half w_1_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 1)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_1_0;
  }
  __syncthreads();
  C[((int)blockIdx.x)] = (half)(((volatile half*)red_buf0)[0]);
}


top1: 0.08790016174316406 	top10: 0.08464178442955017
--------------------------------------------------------------------------------
best config: {<Node, roller_matmul>: {'block': [1, 1], 'thread': [1, 1], 'rstep': [4096], 'reduce_thread': [128], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
best latency: 0.08464178442955017
{<Node, roller_matmul>: {'block': [1, 14], 'thread': [1, 14], 'rstep': [512], 'reduce_thread': [8], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
0.3493806719779968
{<Node, roller_matmul>: {'block': [1, 7], 'thread': [1, 7], 'rstep': [1024], 'reduce_thread': [16], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
0.3035636246204376
{<Node, roller_matmul>: {'block': [1, 8], 'thread': [1, 8], 'rstep': [1024], 'reduce_thread': [16], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.2993558645248413
{<Node, roller_matmul>: {'block': [1, 16], 'thread': [1, 16], 'rstep': [512], 'reduce_thread': [8], 'block_order': <NoRasterization>, 'vectorize': {'A': 4, 'B': 8}}}
0.34951233863830566
{<Node, roller_matmul>: {'block': [1, 4], 'thread': [1, 4], 'rstep': [2048], 'reduce_thread': [32], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.28901809453964233
{<Node, roller_matmul>: {'block': [1, 28], 'thread': [1, 28], 'rstep': [256], 'reduce_thread': [4], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
0.5727793574333191
{<Node, roller_matmul>: {'block': [1, 32], 'thread': [1, 32], 'rstep': [256], 'reduce_thread': [4], 'block_order': <NoRasterization>, 'vectorize': {'A': 2, 'B': 8}}}
0.5586909651756287
{<Node, roller_matmul>: {'block': [1, 2], 'thread': [1, 2], 'rstep': [4096], 'reduce_thread': [64], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.2895945906639099
{<Node, roller_matmul>: {'block': [1, 112], 'thread': [1, 112], 'rstep': [64], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
0.6673704385757446
{<Node, roller_matmul>: {'block': [1, 56], 'thread': [1, 56], 'rstep': [128], 'reduce_thread': [2], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
1.011738896369934
{<Node, roller_matmul>: {'block': [1, 128], 'thread': [1, 128], 'rstep': [64], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
0.7119981050491333
{<Node, roller_matmul>: {'block': [1, 64], 'thread': [1, 64], 'rstep': [128], 'reduce_thread': [2], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
1.102543592453003
{<Node, roller_matmul>: {'block': [1, 1], 'thread': [1, 1], 'rstep': [4096], 'reduce_thread': [128], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.28497689962387085
{<Node, roller_matmul>: {'block': [1, 224], 'thread': [1, 112], 'rstep': [64], 'block_order': <NoRasterization>, 'step': [1, 2], 'vectorize': {'B': 8}}}
0.8918575048446655
{<Node, roller_matmul>: {'block': [1, 256], 'thread': [1, 128], 'rstep': [64], 'block_order': <NoRasterization>, 'step': [1, 2], 'vectorize': {'B': 8}}}
1.0027520656585693
best code __global__ void __launch_bounds__(128) Fused(half* __restrict__ A, half* __restrict__ B, half* __restrict__ C) {
  
  half normal_reduce_temp0[1];
  __shared__ half A_shared[4096];
  __shared__ half B_shared[4096];
  __shared__ half red_buf0[128];
  normal_reduce_temp0[0] = __float2half_rn(0.000000e+00f);
  for (int k_outer = 0; k_outer < 2; ++k_outer) {
    __syncthreads();
    *(uint4*)(A_shared + (((int)threadIdx.x) * 8)) = *(uint4*)(A + ((k_outer * 4096) + (((int)threadIdx.x) * 8)));
    *(uint4*)(A_shared + ((((int)threadIdx.x) * 8) + 1024)) = *(uint4*)(A + (((k_outer * 4096) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(A_shared + ((((int)threadIdx.x) * 8) + 2048)) = *(uint4*)(A + (((k_outer * 4096) + (((int)threadIdx.x) * 8)) + 2048));
    *(uint4*)(A_shared + ((((int)threadIdx.x) * 8) + 3072)) = *(uint4*)(A + (((k_outer * 4096) + (((int)threadIdx.x) * 8)) + 3072));
    *(uint4*)(B_shared + (((int)threadIdx.x) * 8)) = *(uint4*)(B + (((((int)blockIdx.x) * 8192) + (k_outer * 4096)) + (((int)threadIdx.x) * 8)));
    *(uint4*)(B_shared + ((((int)threadIdx.x) * 8) + 1024)) = *(uint4*)(B + ((((((int)blockIdx.x) * 8192) + (k_outer * 4096)) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(B_shared + ((((int)threadIdx.x) * 8) + 2048)) = *(uint4*)(B + ((((((int)blockIdx.x) * 8192) + (k_outer * 4096)) + (((int)threadIdx.x) * 8)) + 2048));
    *(uint4*)(B_shared + ((((int)threadIdx.x) * 8) + 3072)) = *(uint4*)(B + ((((((int)blockIdx.x) * 8192) + (k_outer * 4096)) + (((int)threadIdx.x) * 8)) + 3072));
    __syncthreads();
    for (int k_inner_outer = 0; k_inner_outer < 32; ++k_inner_outer) {
      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + (A_shared[((k_inner_outer * 128) + ((int)threadIdx.x))] * B_shared[((k_inner_outer * 128) + ((int)threadIdx.x))]));
    }
  }
  __syncthreads();
  ((volatile half*)red_buf0)[((int)threadIdx.x)] = normal_reduce_temp0[0];
  __syncthreads();
  if (((int)threadIdx.x) < 64) {
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 64)]));
  }
  __syncthreads();
  if (((int)threadIdx.x) < 32) {
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 32)]));
  }
  __syncthreads();
  if (((int)threadIdx.x) < 16) {
    half w_16_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 16)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_16_0;
    half w_8_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 8)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_8_0;
    half w_4_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 4)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_4_0;
    half w_2_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 2)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_2_0;
    half w_1_0 = ((half)(((volatile half*)red_buf0)[((int)threadIdx.x)]) + (half)(((volatile half*)red_buf0)[(((int)threadIdx.x) + 1)]));
    ((volatile half*)red_buf0)[((int)threadIdx.x)] = w_1_0;
  }
  __syncthreads();
  C[((int)blockIdx.x)] = (half)(((volatile half*)red_buf0)[0]);
}


top1: 0.3493806719779968 	top10: 0.28497689962387085
--------------------------------------------------------------------------------
best config: {<Node, roller_matmul>: {'block': [1, 1], 'thread': [1, 1], 'rstep': [4096], 'reduce_thread': [128], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
best latency: 0.28497689962387085
{<Node, roller_matmul>: {'block': [1, 4], 'thread': [1, 4], 'rstep': [2048], 'reduce_thread': [32], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.29207760095596313
{<Node, roller_matmul>: {'block': [1, 8], 'thread': [1, 8], 'rstep': [1024], 'reduce_thread': [16], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.30334463715553284
{<Node, roller_matmul>: {'block': [1, 2], 'thread': [1, 2], 'rstep': [4096], 'reduce_thread': [64], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.29315730929374695
{<Node, roller_matmul>: {'block': [1, 32], 'thread': [1, 32], 'rstep': [256], 'reduce_thread': [4], 'block_order': <NoRasterization>, 'vectorize': {'A': 2, 'B': 8}}}
0.6939977407455444
{<Node, roller_matmul>: {'block': [1, 16], 'thread': [1, 16], 'rstep': [512], 'reduce_thread': [8], 'block_order': <NoRasterization>, 'vectorize': {'A': 4, 'B': 8}}}
0.37404516339302063
{<Node, roller_matmul>: {'block': [1, 1], 'thread': [1, 1], 'rstep': [4096], 'reduce_thread': [128], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.330645889043808
{<Node, roller_matmul>: {'block': [1, 64], 'thread': [1, 64], 'rstep': [128], 'reduce_thread': [2], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
1.6082789897918701
{<Node, roller_matmul>: {'block': [1, 128], 'thread': [1, 128], 'rstep': [64], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
1.1047416925430298
{<Node, roller_matmul>: {'block': [1, 256], 'thread': [1, 128], 'rstep': [64], 'block_order': <NoRasterization>, 'step': [1, 2], 'vectorize': {'B': 8}}}
2.0325491428375244
best code __global__ void __launch_bounds__(128) Fused(half* __restrict__ A, half* __restrict__ B, half* __restrict__ C) {
  
  half normal_reduce_temp0[1];
  __shared__ half A_shared[2048];
  __shared__ half B_shared[8192];
  half red_buf0[1];
  normal_reduce_temp0[0] = __float2half_rn(0.000000e+00f);
  for (int k_outer = 0; k_outer < 14; ++k_outer) {
    __syncthreads();
    *(uint4*)(A_shared + ((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8))) = *(uint4*)(A + (((k_outer * 2048) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)));
    *(uint4*)(A_shared + (((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 1024)) = *(uint4*)(A + ((((k_outer * 2048) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(B_shared + ((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8))) = *(uint4*)(B + ((((((int)blockIdx.x) * 114688) + (k_outer * 2048)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 1024)) = *(uint4*)(B + (((((((int)blockIdx.x) * 114688) + (k_outer * 2048)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 2048)) = *(uint4*)(B + (((((((int)blockIdx.x) * 114688) + (k_outer * 2048)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + 28672));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 3072)) = *(uint4*)(B + ((((((((int)blockIdx.x) * 114688) + (((((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 3072) >> 11) * 28672)) + (k_outer * 2048)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 4096)) = *(uint4*)(B + (((((((int)blockIdx.x) * 114688) + (k_outer * 2048)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + 57344));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 5120)) = *(uint4*)(B + ((((((((int)blockIdx.x) * 114688) + (((((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 5120) >> 11) * 28672)) + (k_outer * 2048)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 6144)) = *(uint4*)(B + (((((((int)blockIdx.x) * 114688) + (k_outer * 2048)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + 86016));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 7168)) = *(uint4*)(B + ((((((((int)blockIdx.x) * 114688) + (((((((int)threadIdx.y) * 256) + (((int)threadIdx.x) * 8)) + 7168) >> 11) * 28672)) + (k_outer * 2048)) + (((int)threadIdx.y) * 256)) + (((int)threadIdx.x) * 8)) + 1024));
    __syncthreads();
    for (int k_inner_outer = 0; k_inner_outer < 64; ++k_inner_outer) {
      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + (A_shared[((k_inner_outer * 32) + ((int)threadIdx.x))] * B_shared[(((((int)threadIdx.y) * 2048) + (k_inner_outer * 32)) + ((int)threadIdx.x))]));
    }
  }
  uint mask[1];
  half t0[1];
  red_buf0[0] = normal_reduce_temp0[0];
  mask[0] = (__activemask() & ((uint)0 << ((uint)32 * ((uint)((int)threadIdx.y)))));
  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);
  red_buf0[0] = (red_buf0[0] + t0[0]);
  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);
  red_buf0[0] = (red_buf0[0] + t0[0]);
  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);
  red_buf0[0] = (red_buf0[0] + t0[0]);
  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);
  red_buf0[0] = (red_buf0[0] + t0[0]);
  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);
  red_buf0[0] = (red_buf0[0] + t0[0]);
  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], (((int)threadIdx.y) * 32), 32);
  C[((((int)blockIdx.x) * 4) + ((int)threadIdx.y))] = red_buf0[0];
}


top1: 0.29207760095596313 	top10: 0.29207760095596313
--------------------------------------------------------------------------------
best config: {<Node, roller_matmul>: {'block': [1, 4], 'thread': [1, 4], 'rstep': [2048], 'reduce_thread': [32], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
best latency: 0.29207760095596313
{<Node, roller_matmul>: {'block': [1, 4], 'thread': [1, 4], 'rstep': [2048], 'reduce_thread': [32], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.01252787932753563
{<Node, roller_matmul>: {'block': [1, 2], 'thread': [1, 2], 'rstep': [4096], 'reduce_thread': [64], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.012005114927887917
{<Node, roller_matmul>: {'block': [1, 1], 'thread': [1, 1], 'rstep': [4096], 'reduce_thread': [128], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.012970666401088238
{<Node, roller_matmul>: {'block': [1, 8], 'thread': [1, 8], 'rstep': [1024], 'reduce_thread': [16], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
0.018240129575133324
{<Node, roller_matmul>: {'block': [1, 16], 'thread': [1, 16], 'rstep': [512], 'reduce_thread': [8], 'block_order': <NoRasterization>, 'vectorize': {'A': 4, 'B': 8}}}
0.026312164962291718
{<Node, roller_matmul>: {'block': [1, 32], 'thread': [1, 32], 'rstep': [256], 'reduce_thread': [4], 'block_order': <NoRasterization>, 'vectorize': {'A': 2, 'B': 8}}}
0.07126376032829285
{<Node, roller_matmul>: {'block': [1, 64], 'thread': [1, 64], 'rstep': [128], 'reduce_thread': [2], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
0.23314465582370758
{<Node, roller_matmul>: {'block': [1, 128], 'thread': [1, 128], 'rstep': [64], 'block_order': <NoRasterization>, 'vectorize': {'B': 8}}}
0.2596151530742645
{<Node, roller_matmul>: {'block': [1, 256], 'thread': [1, 128], 'rstep': [64], 'block_order': <NoRasterization>, 'step': [1, 2], 'vectorize': {'B': 8}}}
0.4847562313079834
best code __global__ void __launch_bounds__(128) Fused(half* __restrict__ A, half* __restrict__ B, half* __restrict__ C) {
  
  half normal_reduce_temp0[1];
  __shared__ half A_shared[4096];
  __shared__ half B_shared[8192];
  __shared__ half red_buf0[128];
  normal_reduce_temp0[0] = __float2half_rn(0.000000e+00f);
  for (int k_outer = 0; k_outer < 2; ++k_outer) {
    __syncthreads();
    *(uint4*)(A_shared + ((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8))) = *(uint4*)(A + (((k_outer * 4096) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)));
    *(uint4*)(A_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 1024)) = *(uint4*)(A + ((((k_outer * 4096) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(A_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 2048)) = *(uint4*)(A + ((((k_outer * 4096) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 2048));
    *(uint4*)(A_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 3072)) = *(uint4*)(A + ((((k_outer * 4096) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 3072));
    *(uint4*)(B_shared + ((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8))) = *(uint4*)(B + ((((((int)blockIdx.x) * 16384) + (k_outer * 4096)) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 1024)) = *(uint4*)(B + (((((((int)blockIdx.x) * 16384) + (k_outer * 4096)) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 2048)) = *(uint4*)(B + (((((((int)blockIdx.x) * 16384) + (k_outer * 4096)) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 2048));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 3072)) = *(uint4*)(B + (((((((int)blockIdx.x) * 16384) + (k_outer * 4096)) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 3072));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 4096)) = *(uint4*)(B + (((((((int)blockIdx.x) * 16384) + (k_outer * 4096)) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 8192));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 5120)) = *(uint4*)(B + ((((((((int)blockIdx.x) * 16384) + (((((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 5120) >> 12) * 8192)) + (k_outer * 4096)) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 1024));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 6144)) = *(uint4*)(B + ((((((((int)blockIdx.x) * 16384) + (((((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 6144) >> 12) * 8192)) + (k_outer * 4096)) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 2048));
    *(uint4*)(B_shared + (((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 7168)) = *(uint4*)(B + ((((((((int)blockIdx.x) * 16384) + (((((((int)threadIdx.y) * 512) + (((int)threadIdx.x) * 8)) + 7168) >> 12) * 8192)) + (k_outer * 4096)) + (((int)threadIdx.y) * 512)) + (((int)threadIdx.x) * 8)) + 3072));
    __syncthreads();
    for (int k_inner_outer = 0; k_inner_outer < 64; ++k_inner_outer) {
      normal_reduce_temp0[0] = (normal_reduce_temp0[0] + (A_shared[((k_inner_outer * 64) + ((int)threadIdx.x))] * B_shared[(((((int)threadIdx.y) * 4096) + (k_inner_outer * 64)) + ((int)threadIdx.x))]));
    }
  }
  __syncthreads();
  ((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))] = normal_reduce_temp0[0];
  __syncthreads();
  if (((int)threadIdx.x) < 32) {
    ((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))] = ((half)(((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))]) + (half)(((volatile half*)red_buf0)[(((((int)threadIdx.y) * 64) + ((int)threadIdx.x)) + 32)]));
  }
  __syncthreads();
  if (((int)threadIdx.x) < 16) {
    half w_16_0 = ((half)(((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))]) + (half)(((volatile half*)red_buf0)[(((((int)threadIdx.y) * 64) + ((int)threadIdx.x)) + 16)]));
    ((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))] = w_16_0;
    half w_8_0 = ((half)(((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))]) + (half)(((volatile half*)red_buf0)[(((((int)threadIdx.y) * 64) + ((int)threadIdx.x)) + 8)]));
    ((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))] = w_8_0;
    half w_4_0 = ((half)(((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))]) + (half)(((volatile half*)red_buf0)[(((((int)threadIdx.y) * 64) + ((int)threadIdx.x)) + 4)]));
    ((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))] = w_4_0;
    half w_2_0 = ((half)(((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))]) + (half)(((volatile half*)red_buf0)[(((((int)threadIdx.y) * 64) + ((int)threadIdx.x)) + 2)]));
    ((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))] = w_2_0;
    half w_1_0 = ((half)(((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))]) + (half)(((volatile half*)red_buf0)[(((((int)threadIdx.y) * 64) + ((int)threadIdx.x)) + 1)]));
    ((volatile half*)red_buf0)[((((int)threadIdx.y) * 64) + ((int)threadIdx.x))] = w_1_0;
  }
  __syncthreads();
  C[((((int)blockIdx.x) * 2) + ((int)threadIdx.y))] = (half)(((volatile half*)red_buf0)[(((int)threadIdx.y) * 64)]);
}


top1: 0.01252787932753563 	top10: 0.012005114927887917
--------------------------------------------------------------------------------
best config: {<Node, roller_matmul>: {'block': [1, 2], 'thread': [1, 2], 'rstep': [4096], 'reduce_thread': [64], 'block_order': <NoRasterization>, 'vectorize': {'A': 8, 'B': 8}}}
best latency: 0.012005114927887917
1_8192_8192	0.08464178442955017
1_28672_8192	0.28497689962387085
1_8192_28672	0.29207760095596313
1_1024_8192	0.012005114927887917
