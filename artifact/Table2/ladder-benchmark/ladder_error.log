['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 4, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 3], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 4, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 4, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 4, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 7, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 7, 4, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 2, 28, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 2, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 28, 2, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 28, 2, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 2, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 2, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 14, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 14, 2, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 7, 4, 58], 'thread': [1, 1, 2, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 7, 4, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 4, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 4, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 2, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 2, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 7, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 7, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 14, 2, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 14, 2, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 2, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 2, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 7, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 7, 2, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 2, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 2, 4, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 4, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 4, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [64, 1, 2, 58], 'thread': [64, 1, 1, 2], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [64, 1, 2, 58], 'thread': [64, 1, 1, 2], 'rstep': [1, 1, 2], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [64, 2, 1, 58], 'thread': [64, 1, 1, 2], 'rstep': [1, 1], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [64, 2, 1, 58], 'thread': [64, 1, 1, 2], 'rstep': [1, 1, 2], 'step': [1, 2, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 1, 28, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 1, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 28, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 28, 1, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 1, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 1, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 14, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 14, 1, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [8, 2, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [8, 2, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 1, 28, 58], 'thread': [1, 1, 2, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 1, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 28, 1, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 28, 1, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [8, 1, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [8, 1, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [8, 7, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [8, 7, 1, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 1, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 1, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 14, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 14, 1, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 14, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 28, 29], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 24]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 7, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 7, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 28, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 14, 29], 'thread': [1, 7, 14, 1], 'rstep': [1, 1, 24], 'vectorize': {'mediate0': 8}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 7, 29], 'thread': [1, 14, 7, 1], 'rstep': [1, 1, 24], 'vectorize': {'mediate0': 8}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 4, 28, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 4, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 24], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 24], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 4, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 4, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 28, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 14, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 28, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 7, 28, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 14, 14, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 28, 7, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 2, 1, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 4, 14, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 4, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 2, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 2, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 24], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 4, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 2, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 2, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 14, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 22752, 29232)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 38976)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [4, 2, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [4, 2, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 32480)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [8, 1, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [8, 1, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 45472, 68208)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 45472, 48720)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 12992)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 22752, 34104)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 22752, 27608)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 32480)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [8, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [8, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [16, 1, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [16, 1, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 27608)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [4, 4, 28, 58], 'thread': [4, 4, 4, 2], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [4, 4, 28, 58], 'thread': [4, 4, 4, 2], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 51968, 64960)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [8, 2, 28, 58], 'thread': [8, 2, 4, 2], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [8, 2, 28, 58], 'thread': [8, 2, 4, 2], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 51968, 64960)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 17052)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 12180)

['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [3, 3], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_12>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 12992)

['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_12>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 12180)

['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [8, 4, 4, 58], 'thread': [8, 4, 2, 2], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [8, 4, 4, 58], 'thread': [8, 4, 2, 2], 'rstep': [1, 1, 2], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_12>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 17052)

['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 28, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 28, 7, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 4, 28, 58], 'thread': [1, 1, 2, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 4, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 28, 4, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 28, 4, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 14, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 4, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 4, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 14, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 14, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [16, 2, 4, 58], 'thread': [16, 2, 2, 2], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [16, 2, 4, 58], 'thread': [16, 2, 2, 2], 'rstep': [1, 1, 2], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [16, 4, 2, 58], 'thread': [16, 4, 1, 2], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [16, 4, 2, 58], 'thread': [16, 4, 1, 2], 'rstep': [1, 1, 2], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 4, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 4, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 7, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 7, 4, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 4, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 4, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 7, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 7, 4, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 28, 2, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 28, 2, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 2, 28, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 2, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 28, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 28, 2, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 2, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 2, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 14, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 14, 2, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 4, 28, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 28, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 28, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 2, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 14, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 14, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 2, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 2, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 7, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 7, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 4, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 14, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 14, 4, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 4, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 7, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 28, 29], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 2, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 14, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 4, 28, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 4, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 14, 29], 'thread': [1, 7, 14, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 2, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 4, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 4, 28, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 7, 29], 'thread': [1, 14, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 7, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 28, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 4, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 4, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 14, 14, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [4, 2, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 28, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 14, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 1, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 2, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 14, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 28, 4, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 4, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 14, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 7, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 2, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 14, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  14: TVMFuncCall
  13: _ZN3tvm7runtime13PackedFuncObj
  12: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  11: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  10: tvm::ScheduleToModule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply)
  9: tvm::te::InferBound(tvm::te::Schedule const&)
  8: tvm::arith::Analyzer::Simplify(tvm::PrimExpr const&, int)
  7: tvm::arith::CanonicalSimplifier::operator()(tvm::PrimExpr const&)
  6: non-virtual thunk to tvm::arith::CanonicalSimplifier::Impl::VisitExpr(tvm::PrimExpr const&)
  5: tvm::arith::SumExprNode::Normalize() const
  4: tvm::arith::SumExprNode::Normalize_(tvm::runtime::DataType, std::vector<tvm::arith::SplitExpr, std::allocator<tvm::arith::SplitExpr> > const&, long)
  3: tvm::arith::SplitExprNode::NormalizeWithScale(long) const
  2: tvm::PrimExpr tvm::tir::make_const<long, void>(tvm::runtime::DataType, long, tvm::Span)
  1: tvm::PrimExpr tvm::tir::MakeConstScalar<long>(tvm::runtime::DataType, long, tvm::Span)
  0: tvm::IntImm::IntImm(tvm::runtime::DataType, long, tvm::Span)
  File "/root/Ladder/3rdparty/tvm/src/ir/expr.cc", line 93
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value < 1LL << (dtype.bits() - 1) (2284513280 vs. 2147483648) : ValueError: Literal value 2284513280 exceeds maximum of int32

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 4, 28, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 4, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 2, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 4, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 4, 28, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 7, 28, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 4, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 4, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  14: TVMFuncCall
  13: _ZN3tvm7runtime13PackedFuncObj
  12: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  11: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  10: tvm::ScheduleToModule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply)
  9: tvm::te::InferBound(tvm::te::Schedule const&)
  8: tvm::arith::Analyzer::Simplify(tvm::PrimExpr const&, int)
  7: tvm::arith::CanonicalSimplifier::operator()(tvm::PrimExpr const&)
  6: non-virtual thunk to tvm::arith::CanonicalSimplifier::Impl::VisitExpr(tvm::PrimExpr const&)
  5: tvm::arith::SumExprNode::Normalize() const
  4: tvm::arith::SumExprNode::Normalize_(tvm::runtime::DataType, std::vector<tvm::arith::SplitExpr, std::allocator<tvm::arith::SplitExpr> > const&, long)
  3: tvm::arith::SplitExprNode::NormalizeWithScale(long) const
  2: tvm::PrimExpr tvm::tir::make_const<long, void>(tvm::runtime::DataType, long, tvm::Span)
  1: tvm::PrimExpr tvm::tir::MakeConstScalar<long>(tvm::runtime::DataType, long, tvm::Span)
  0: tvm::IntImm::IntImm(tvm::runtime::DataType, long, tvm::Span)
  File "/root/Ladder/3rdparty/tvm/src/ir/expr.cc", line 93
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value < 1LL << (dtype.bits() - 1) (2282434560 vs. 2147483648) : ValueError: Literal value 2282434560 exceeds maximum of int32

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 14, 14, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  16: TVMFuncCall
  15: _ZN3tvm7runtime13PackedFuncObj
  14: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  13: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  12: tvm::ScheduleToModule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply)
  11: tvm::te::InferBound(tvm::te::Schedule const&)
  10: tvm::te::PassDownDomain(tvm::te::Stage const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*, tvm::arith::Analyzer*, bool)
  9: tvm::te::PassDownDomain(tvm::te::Stage const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*, tvm::arith::Analyzer*, bool)::{lambda(tvm::PrimExpr const&, tvm::PrimExpr const&)#1}::operator()(tvm::PrimExpr const&, tvm::PrimExpr const&) const [clone .isra.0]
  8: tvm::arith::Analyzer::Simplify(tvm::PrimExpr const&, int)
  7: tvm::arith::CanonicalSimplifier::operator()(tvm::PrimExpr const&)
  6: non-virtual thunk to tvm::arith::CanonicalSimplifier::Impl::VisitExpr(tvm::PrimExpr const&)
  5: tvm::arith::SumExprNode::Normalize() const
  4: tvm::arith::SumExprNode::Normalize_(tvm::runtime::DataType, std::vector<tvm::arith::SplitExpr, std::allocator<tvm::arith::SplitExpr> > const&, long)
  3: tvm::arith::SplitExprNode::NormalizeWithScale(long) const
  2: tvm::PrimExpr tvm::tir::make_const<long, void>(tvm::runtime::DataType, long, tvm::Span)
  1: tvm::PrimExpr tvm::tir::MakeConstScalar<long>(tvm::runtime::DataType, long, tvm::Span)
  0: tvm::IntImm::IntImm(tvm::runtime::DataType, long, tvm::Span)
  File "/root/Ladder/3rdparty/tvm/src/ir/expr.cc", line 93
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value < 1LL << (dtype.bits() - 1) (16562721280 vs. 2147483648) : ValueError: Literal value 16562721280 exceeds maximum of int32

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [4, 2, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 28, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 14, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 1, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 2, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 28, 4, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  14: TVMFuncCall
  13: _ZN3tvm7runtime13PackedFuncObj
  12: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  11: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  10: tvm::ScheduleToModule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply)
  9: tvm::te::InferBound(tvm::te::Schedule const&)
  8: tvm::arith::Analyzer::Simplify(tvm::PrimExpr const&, int)
  7: tvm::arith::CanonicalSimplifier::operator()(tvm::PrimExpr const&)
  6: non-virtual thunk to tvm::arith::CanonicalSimplifier::Impl::VisitExpr(tvm::PrimExpr const&)
  5: tvm::arith::SumExprNode::Normalize() const
  4: tvm::arith::SumExprNode::Normalize_(tvm::runtime::DataType, std::vector<tvm::arith::SplitExpr, std::allocator<tvm::arith::SplitExpr> > const&, long)
  3: tvm::arith::SplitExprNode::NormalizeWithScale(long) const
  2: tvm::PrimExpr tvm::tir::make_const<long, void>(tvm::runtime::DataType, long, tvm::Span)
  1: tvm::PrimExpr tvm::tir::MakeConstScalar<long>(tvm::runtime::DataType, long, tvm::Span)
  0: tvm::IntImm::IntImm(tvm::runtime::DataType, long, tvm::Span)
  File "/root/Ladder/3rdparty/tvm/src/ir/expr.cc", line 93
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value < 1LL << (dtype.bits() - 1) (2282434560 vs. 2147483648) : ValueError: Literal value 2282434560 exceeds maximum of int32

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [32, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [32, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [32, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [32, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 2, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [64, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [64, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [16, 2, 1, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [16, 2, 1, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [32, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [32, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 2, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 7, 2, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [8, 2, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [8, 2, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [4, 1, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [4, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [8, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [8, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [8, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [8, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 1, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 7, 1, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [16, 2, 2, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [16, 2, 2, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 11392, 12992)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [64, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [64, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 29], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [64, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [64, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 29], 'step': [1, 2, 1, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [128, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [128, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 2, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 2, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 14, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 14, 2, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [4, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [4, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [4, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [4, 7, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 14, 29], 'thread': [1, 7, 14, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 7, 29], 'thread': [1, 14, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 2, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 2, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 2, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 14, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 2, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 2, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 14, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 7, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 7, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 14, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 2, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 1, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 1, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 22752, 29232)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 32480)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 45472, 68208)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [8, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [8, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 22752, 34104)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 11392, 12992)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [8, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [8, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [16, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [16, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 27608)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [1, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [1, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 1632, 1856)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [8, 2, 14, 116], 'thread': [8, 2, 2, 4], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [8, 2, 14, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 51968, 64960)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 45472, 56840)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 45472, 68208)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [16, 1, 14, 116], 'thread': [16, 1, 2, 4], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [16, 1, 14, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 51968, 61712)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [4, 14, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [4, 14, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 32480)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [1, 14, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [1, 14, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 2, 2, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 2, 2, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 2, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 14, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 14, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_33>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 11392, 12992)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 7, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [32, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [32, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [32, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [32, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 2, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 3], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_33>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [1, 14, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [1, 14, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 7, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 14, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 1, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 14, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 14, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 2, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 2, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 14, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 14, 2, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 7, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 2, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 7, 2, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 3], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_33>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 2, 1, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 2, 1, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_33>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 1, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 14, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 14, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 14, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 14, 1, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [32, 2, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [32, 2, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [64, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [64, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 14, 29], 'thread': [1, 7, 14, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 2, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 2, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 14, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 7, 29], 'thread': [1, 14, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 7, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 2, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 14, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 2, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 1, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 7, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 1, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 2, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 7, 29], 'thread': [2, 7, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 2, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [8, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [8, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [8, 2, 14, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [1, 14, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [1, 14, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 14, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [1, 2, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 2, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [4, 7, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [1, 2, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 14, 14, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [4, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 14, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 2, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [1, 1, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 1, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [1, 2, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [2, 2, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [8, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [4, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_63', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_63__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_64>: {'block': [8, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_67', 'nn_conv2d_multiply_add_68']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_67>: {'block': [1, 15, 15, 4], 'thread': [1, 1, 1, 4], 'rstep': [1, 1, 58], 'vectorize': {'p1': 2}}, <Node, nn_conv2d_multiply_add_68>: {'block': [1, 7, 7, 4], 'thread': [1, 1, 1, 4], 'rstep': [3, 3]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_67', 'nn_conv2d_multiply_add_68']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_67>: {'block': [2, 15, 15, 4], 'thread': [2, 1, 1, 4], 'rstep': [1, 1, 58]}, <Node, nn_conv2d_multiply_add_68>: {'block': [2, 7, 7, 4], 'thread': [2, 1, 1, 4], 'rstep': [1, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_67', 'nn_conv2d_multiply_add_68']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_67>: {'block': [2, 15, 15, 2], 'thread': [2, 1, 1, 2], 'rstep': [1, 1, 58]}, <Node, nn_conv2d_multiply_add_68>: {'block': [2, 7, 7, 2], 'thread': [2, 1, 1, 2], 'rstep': [1, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_67', 'nn_conv2d_multiply_add_68']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_67>: {'block': [2, 15, 15, 1], 'thread': [2, 1, 1, 1], 'rstep': [1, 1, 58], 'vectorize': {'pad_temp': 2}}, <Node, nn_conv2d_multiply_add_68>: {'block': [2, 7, 7, 1], 'thread': [2, 1, 1, 1], 'rstep': [1, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_68', 'nn_conv2d_multiply_add_nn_relu_69']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_68>: {'block': [16, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_69>: {'block': [16, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_69>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_68', 'nn_conv2d_multiply_add_nn_relu_69']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_68>: {'block': [32, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_69>: {'block': [32, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 8], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_68', 'nn_conv2d_multiply_add_nn_relu_69']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_68>: {'block': [2, 1, 7, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 4, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_69>: {'block': [2, 1, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_69>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 6496, 9744)

['nn_conv2d_multiply_add_68', 'nn_conv2d_multiply_add_nn_relu_69']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_68>: {'block': [2, 7, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 4, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_69>: {'block': [2, 7, 1, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_69>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 6496, 9744)

['nn_conv2d_multiply_add_68', 'nn_conv2d_multiply_add_nn_relu_69']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_68>: {'block': [64, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_69>: {'block': [64, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 4], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_68', 'nn_conv2d_multiply_add_nn_relu_69']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_68>: {'block': [2, 1, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 4, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_69>: {'block': [2, 1, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_69>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 928, 1856)

['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [1, 7, 7, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [2, 7, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 7, 1, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 7, 7, 29], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [2, 7, 7, 29], 'thread': [2, 7, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [1, 1, 7, 58], 'thread': [1, 1, 7, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [1, 7, 1, 58], 'thread': [1, 7, 1, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [2, 1, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [2, 7, 1, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [8, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [8, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [2, 1, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [2, 7, 1, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 7, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [1, 1, 7, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [1, 7, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [8, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [8, 7, 1, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [1, 7, 7, 8], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [8, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [8, 7, 7, 29], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [2, 1, 1, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [2, 1, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [2, 7, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 1, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [4, 7, 1, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_66', 'concatenate_layout_transform_reshape_transpose_reshape_70']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_66__concatenate_layout_transform_reshape_transpose_reshape_70>: {'block': [8, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [2, 7, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [2, 7, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 45472, 68208)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [4, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [4, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 8], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 12992, 16240)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [2, 1, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [2, 1, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 6496, 9744)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [8, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [8, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 8], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [16, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [16, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 7424, 8352)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [16, 1, 7, 232], 'thread': [16, 1, 1, 8], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [16, 1, 7, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 51968, 61712)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [4, 7, 1, 232], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [4, 7, 1, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 8], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 12992, 16240)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [2, 7, 1, 232], 'thread': [2, 1, 1, 58], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [2, 7, 1, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 6496, 9744)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [2, 1, 1, 232], 'thread': [2, 1, 1, 58], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [2, 1, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 928, 1856)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [8, 7, 1, 232], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [8, 7, 1, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 8], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_71', 'nn_conv2d_multiply_add_nn_relu_72']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_71>: {'block': [16, 7, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_72>: {'block': [16, 7, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_72>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 51968, 61712)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [4, 1, 7, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 8, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [4, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 8], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 12992, 16240)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [4, 7, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 8, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [4, 7, 1, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 8], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 12992, 16240)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [16, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [16, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [2, 7, 7, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 4, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [2, 7, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 45472, 68208)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [8, 1, 7, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 8, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [8, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 8], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 25984, 29232)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [8, 7, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 8, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [8, 7, 1, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 8], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 25984, 29232)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [32, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [32, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 8], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [2, 1, 7, 232], 'thread': [1, 1, 1, 116], 'rstep': [3, 1], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 4, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [2, 1, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 6496, 9744)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [2, 7, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 4, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [2, 7, 1, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 6496, 9744)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [16, 1, 7, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [16, 1, 7, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 51968, 61712)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [16, 7, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [16, 7, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 51968, 61712)

['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [64, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [64, 1, 1, 232], 'thread': [16, 1, 1, 8], 'rstep': [1, 1, 4], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_73', 'nn_conv2d_multiply_add_nn_relu_74']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_73>: {'block': [2, 1, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [1, 1, 1, 2], 'vectorize': {'PaddedInput': 4, 'p1': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_74>: {'block': [2, 1, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_74>, Tensor(shape=[128, 7, 7, 232], op.name=p0), 928, 1856)

['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [1, 7, 7, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 7, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 7, 7, 29], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 7, 7, 29], 'thread': [2, 7, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 7, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 1, 7, 232], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 1, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [1, 1, 7, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [8, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [8, 7, 7, 29], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [2, 1, 1, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [8, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [8, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 1, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [8, 1, 7, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 1, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [1, 1, 7, 58], 'thread': [1, 1, 7, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 7, 7, 8], 'thread': [2, 7, 1, 8], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [1, 7, 7, 8], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 7, 7, 8], 'thread': [2, 7, 1, 8], 'rstep': [1, 1, 58], 'step': [2, 1, 1, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [16, 1, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [8, 1, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [16, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 7, 1, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [1, 7, 1, 232], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 7, 1, 232], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 7, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [1, 7, 1, 58], 'thread': [1, 7, 1, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [4, 1, 7, 29], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_74', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_74__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_75>: {'block': [2, 1, 7, 29], 'thread': [1, 1, 7, 29], 'rstep': [1, 1, 232], 'step': [2, 1, 1, 1], 'vectorize': {'mediate0': 8}}}
Compiler timeout.
['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
None
16 is not in list
['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [4, 16, 16, 16], 'warp': [2, 8, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [8, 8, 16, 16], 'warp': [4, 4, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [4, 8, 16, 16], 'warp': [2, 4, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [8, 16, 16, 16], 'warp': [4, 8, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [7, 8, 16, 16], 'warp': [7, 2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [4, 4, 16, 16], 'warp': [2, 2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [7, 4, 16, 16], 'warp': [7, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [8, 4, 16, 16], 'warp': [4, 2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [14, 4, 16, 16], 'warp': [7, 2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [4, 32, 16, 16], 'warp': [2, 16, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [2, 16, 16, 16], 'warp': [1, 8, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [7, 2, 16, 16], 'warp': [1, 2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [2, 8, 16, 16], 'warp': [1, 4, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [14, 8, 16, 16], 'warp': [7, 4, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [14, 2, 16, 16], 'warp': [7, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [4, 2, 16, 16], 'warp': [2, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [8, 32, 16, 16], 'warp': [4, 16, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [7, 16, 16, 16], 'warp': [7, 4, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [2, 4, 16, 16], 'warp': [1, 2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [28, 2, 16, 16], 'warp': [14, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [28, 4, 16, 16], 'warp': [14, 2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [8, 2, 16, 16], 'warp': [4, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [2, 2, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [14, 16, 16, 16], 'warp': [7, 8, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [7, 1, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [28, 8, 16, 16], 'warp': [14, 4, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [14, 1, 16, 16], 'warp': [2, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [4, 1, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [1, 4, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [1, 16, 16, 16], 'warp': [1, 4, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [1, 8, 16, 16], 'warp': [1, 2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [2, 32, 16, 16], 'warp': [1, 16, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [1, 2, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [28, 1, 16, 16], 'warp': [7, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [1, 1, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [7, 32, 16, 16], 'warp': [7, 8, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [2, 1, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [49, 4, 16, 16], 'warp': [49, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [8, 1, 16, 16], 'warp': [2, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86', 'reshape_layout_transform_multiply_add_nn_relu_87']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86__reshape_layout_transform_multiply_add_nn_relu_87>: {'block': [49, 2, 16, 16], 'warp': [7, 2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {4: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['ladder_perfect_im2col_quant_conv_86']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86>: {'block': [14, 1, 16, 16], 'warp': [2, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {2: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/tir_base.py", line 81, in build
    mod = tvm.build(self.sche.mod["main"], self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  83: TVMFuncCall
  82: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  81: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  80: tvm::SplitMixedModule(tvm::IRModule, tvm::Target const&, tvm::Target const&)
  79: tvm::ApplyPasses(tvm::IRModule, tvm::transform::Sequential)
  78: tvm::transform::Pass::operator()(tvm::IRModule) const
  77: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  76: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  75: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  74: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  73: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform18InjectPTXAsyncCopyEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  72: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  71: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  70: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  69: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  68: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  67: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  66: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  65: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  64: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  63: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  62: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  61: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  60: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  59: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  58: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  57: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  56: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  55: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  54: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  53: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  52: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  51: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  50: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  49: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  48: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  47: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  46: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  45: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  44: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  43: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  42: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  41: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  40: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  39: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  38: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  37: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  36: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  35: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  30: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  29: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  28: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  27: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  26: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  25: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  24: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  23: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  18: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  16: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  14: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  13: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  12: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  11: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  10: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  9: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  8: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  7: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  6: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  5: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  4: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  3: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  2: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  1: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::BufferStoreNode const*)
  0: tvm::tir::PTXAsyncCopyInjector::InjectPTX(tvm::tir::BufferLoadNode const*, tvm::tir::BufferStoreNode const*, bool, tvm::PrimExpr)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/inject_ptx_async_copy.cc", line 54
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (load->indices[0]->dtype.lanes() == store->indices[0]->dtype.lanes()) is false: 4:1

['ladder_perfect_im2col_quant_conv_86']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86>: {'block': [28, 1, 16, 16], 'warp': [7, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {2: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/tir_base.py", line 81, in build
    mod = tvm.build(self.sche.mod["main"], self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  83: TVMFuncCall
  82: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  81: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  80: tvm::SplitMixedModule(tvm::IRModule, tvm::Target const&, tvm::Target const&)
  79: tvm::ApplyPasses(tvm::IRModule, tvm::transform::Sequential)
  78: tvm::transform::Pass::operator()(tvm::IRModule) const
  77: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  76: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  75: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  74: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  73: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform18InjectPTXAsyncCopyEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  72: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  71: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  70: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  69: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  68: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  67: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  66: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  65: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  64: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  63: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  62: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  61: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  60: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  59: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  58: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  57: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  56: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  55: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  54: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  53: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  52: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  51: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  50: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  49: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  48: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  47: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  46: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  45: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  44: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  43: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  42: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  41: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  40: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  39: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  38: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  37: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  36: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  35: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  30: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  29: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  28: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  27: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  26: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  25: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  24: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  23: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  18: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  16: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  14: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  13: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  12: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  11: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  10: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  9: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  8: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  7: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  6: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  5: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  4: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  3: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  2: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  1: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::BufferStoreNode const*)
  0: tvm::tir::PTXAsyncCopyInjector::InjectPTX(tvm::tir::BufferLoadNode const*, tvm::tir::BufferStoreNode const*, bool, tvm::PrimExpr)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/inject_ptx_async_copy.cc", line 54
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (load->indices[0]->dtype.lanes() == store->indices[0]->dtype.lanes()) is false: 4:1

['ladder_perfect_im2col_quant_conv_86']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86>: {'block': [7, 1, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {2: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/tir_base.py", line 81, in build
    mod = tvm.build(self.sche.mod["main"], self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  83: TVMFuncCall
  82: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  81: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  80: tvm::SplitMixedModule(tvm::IRModule, tvm::Target const&, tvm::Target const&)
  79: tvm::ApplyPasses(tvm::IRModule, tvm::transform::Sequential)
  78: tvm::transform::Pass::operator()(tvm::IRModule) const
  77: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  76: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  75: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  74: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  73: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform18InjectPTXAsyncCopyEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  72: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  71: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  70: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  69: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  68: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  67: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  66: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  65: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  64: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  63: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  62: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  61: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  60: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  59: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  58: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  57: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  56: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  55: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  54: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  53: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  52: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  51: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  50: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  49: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  48: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  47: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  46: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  45: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  44: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  43: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  42: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  41: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  40: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  39: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  38: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  37: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  36: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  35: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  30: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  29: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  28: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  27: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  26: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  25: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  24: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  23: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  18: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  16: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  14: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  13: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  12: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  11: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  10: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  9: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  8: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  7: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  6: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  5: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  4: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  3: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  2: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  1: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::BufferStoreNode const*)
  0: tvm::tir::PTXAsyncCopyInjector::InjectPTX(tvm::tir::BufferLoadNode const*, tvm::tir::BufferStoreNode const*, bool, tvm::PrimExpr)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/inject_ptx_async_copy.cc", line 54
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (load->indices[0]->dtype.lanes() == store->indices[0]->dtype.lanes()) is false: 4:1

['ladder_perfect_im2col_quant_conv_86']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86>: {'block': [4, 1, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {2: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/tir_base.py", line 81, in build
    mod = tvm.build(self.sche.mod["main"], self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  83: TVMFuncCall
  82: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  81: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  80: tvm::SplitMixedModule(tvm::IRModule, tvm::Target const&, tvm::Target const&)
  79: tvm::ApplyPasses(tvm::IRModule, tvm::transform::Sequential)
  78: tvm::transform::Pass::operator()(tvm::IRModule) const
  77: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  76: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  75: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  74: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  73: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform18InjectPTXAsyncCopyEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  72: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  71: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  70: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  69: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  68: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  67: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  66: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  65: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  64: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  63: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  62: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  61: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  60: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  59: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  58: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  57: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  56: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  55: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  54: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  53: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  52: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  51: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  50: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  49: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  48: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  47: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  46: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  45: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  44: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  43: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  42: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  41: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  40: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  39: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  38: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  37: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  36: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  35: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  30: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  29: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  28: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  27: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  26: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  25: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  24: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  23: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  18: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  16: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  14: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  13: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  12: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  11: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  10: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  9: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  8: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  7: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  6: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  5: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  4: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  3: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  2: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  1: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::BufferStoreNode const*)
  0: tvm::tir::PTXAsyncCopyInjector::InjectPTX(tvm::tir::BufferLoadNode const*, tvm::tir::BufferStoreNode const*, bool, tvm::PrimExpr)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/inject_ptx_async_copy.cc", line 54
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (load->indices[0]->dtype.lanes() == store->indices[0]->dtype.lanes()) is false: 4:1

['ladder_perfect_im2col_quant_conv_86']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86>: {'block': [8, 1, 16, 16], 'warp': [2, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {2: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/tir_base.py", line 81, in build
    mod = tvm.build(self.sche.mod["main"], self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  83: TVMFuncCall
  82: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  81: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  80: tvm::SplitMixedModule(tvm::IRModule, tvm::Target const&, tvm::Target const&)
  79: tvm::ApplyPasses(tvm::IRModule, tvm::transform::Sequential)
  78: tvm::transform::Pass::operator()(tvm::IRModule) const
  77: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  76: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  75: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  74: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  73: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform18InjectPTXAsyncCopyEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  72: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  71: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  70: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  69: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  68: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  67: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  66: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  65: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  64: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  63: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  62: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  61: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  60: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  59: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  58: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  57: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  56: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  55: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  54: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  53: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  52: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  51: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  50: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  49: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  48: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  47: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  46: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  45: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  44: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  43: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  42: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  41: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  40: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  39: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  38: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  37: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  36: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  35: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  30: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  29: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  28: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  27: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  26: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  25: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  24: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  23: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  18: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  16: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  14: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  13: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  12: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  11: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  10: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  9: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  8: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  7: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  6: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  5: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  4: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  3: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  2: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  1: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::BufferStoreNode const*)
  0: tvm::tir::PTXAsyncCopyInjector::InjectPTX(tvm::tir::BufferLoadNode const*, tvm::tir::BufferStoreNode const*, bool, tvm::PrimExpr)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/inject_ptx_async_copy.cc", line 54
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (load->indices[0]->dtype.lanes() == store->indices[0]->dtype.lanes()) is false: 4:1

['ladder_perfect_im2col_quant_conv_86']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86>: {'block': [2, 1, 16, 16], 'warp': [1, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {2: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/tir_base.py", line 81, in build
    mod = tvm.build(self.sche.mod["main"], self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  83: TVMFuncCall
  82: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  81: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  80: tvm::SplitMixedModule(tvm::IRModule, tvm::Target const&, tvm::Target const&)
  79: tvm::ApplyPasses(tvm::IRModule, tvm::transform::Sequential)
  78: tvm::transform::Pass::operator()(tvm::IRModule) const
  77: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  76: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  75: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  74: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  73: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform18InjectPTXAsyncCopyEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  72: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  71: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  70: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  69: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  68: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  67: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  66: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  65: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  64: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  63: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  62: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  61: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  60: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  59: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  58: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  57: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  56: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  55: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  54: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  53: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  52: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  51: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  50: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  49: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  48: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  47: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  46: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  45: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  44: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  43: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  42: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  41: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  40: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  39: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  38: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  37: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  36: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  35: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  30: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  29: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  28: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  27: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  26: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  25: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  24: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  23: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  18: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  16: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  14: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  13: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  12: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  11: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  10: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  9: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  8: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  7: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  6: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  5: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  4: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  3: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  2: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  1: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::BufferStoreNode const*)
  0: tvm::tir::PTXAsyncCopyInjector::InjectPTX(tvm::tir::BufferLoadNode const*, tvm::tir::BufferStoreNode const*, bool, tvm::PrimExpr)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/inject_ptx_async_copy.cc", line 54
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (load->indices[0]->dtype.lanes() == store->indices[0]->dtype.lanes()) is false: 4:1

['ladder_perfect_im2col_quant_conv_86']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_perfect_im2col_quant_conv_86>: {'block': [49, 1, 16, 16], 'warp': [7, 1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [16, 1], 'use_tc': '80', 'strides': {2: <Stride, 2, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/tir_base.py", line 81, in build
    mod = tvm.build(self.sche.mod["main"], self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  83: TVMFuncCall
  82: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  81: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  80: tvm::SplitMixedModule(tvm::IRModule, tvm::Target const&, tvm::Target const&)
  79: tvm::ApplyPasses(tvm::IRModule, tvm::transform::Sequential)
  78: tvm::transform::Pass::operator()(tvm::IRModule) const
  77: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  76: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  75: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  74: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  73: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform18InjectPTXAsyncCopyEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  72: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  71: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  70: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  69: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  68: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  67: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  66: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  65: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  64: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  63: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  62: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  61: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  60: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  59: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  58: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  57: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  56: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  55: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  54: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  53: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  52: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  51: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  50: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  49: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  48: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  47: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  46: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  45: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  44: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  43: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  42: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  41: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  40: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  39: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  38: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  37: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  36: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  35: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  30: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  29: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  28: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  27: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  26: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  25: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  24: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  23: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  18: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  16: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  14: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  13: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  12: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  11: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  10: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  9: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  8: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  7: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::SeqStmtNode const*)
  6: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  5: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  4: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  3: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::AttrStmtNode const*)
  2: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  1: tvm::tir::PTXAsyncCopyInjector::VisitStmt_(tvm::tir::BufferStoreNode const*)
  0: tvm::tir::PTXAsyncCopyInjector::InjectPTX(tvm::tir::BufferLoadNode const*, tvm::tir::BufferStoreNode const*, bool, tvm::PrimExpr)
  File "/root/Ladder/3rdparty/tvm/src/tir/transforms/inject_ptx_async_copy.cc", line 54
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (load->indices[0]->dtype.lanes() == store->indices[0]->dtype.lanes()) is false: 4:1

