['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [1, 8, 1], 'thread': [1, 8, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [2, 4, 1], 'thread': [2, 4, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [4, 2, 1], 'thread': [4, 2, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [8, 1, 1], 'thread': [8, 1, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [1, 4, 1], 'thread': [1, 4, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [2, 2, 1], 'thread': [2, 2, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [4, 1, 1], 'thread': [4, 1, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [1, 2, 1], 'thread': [1, 2, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [2, 1, 1], 'thread': [2, 1, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [1, 1, 1], 'thread': [1, 1, 1], 'rstep': [512], 'reduce_thread': [128], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [1, 32, 1], 'thread': [1, 32, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [2, 16, 1], 'thread': [2, 16, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [4, 8, 1], 'thread': [4, 8, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [8, 4, 1], 'thread': [8, 4, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [16, 2, 1], 'thread': [16, 2, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [32, 1, 1], 'thread': [32, 1, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [1, 16, 1], 'thread': [1, 16, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [2, 8, 1], 'thread': [2, 8, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [4, 4, 1], 'thread': [4, 4, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [8, 2, 1], 'thread': [8, 2, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [16, 1, 1], 'thread': [16, 1, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [1, 64, 1], 'thread': [1, 64, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [2, 32, 1], 'thread': [2, 32, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [4, 16, 1], 'thread': [4, 16, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [8, 8, 1], 'thread': [8, 8, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [16, 4, 1], 'thread': [16, 4, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [32, 2, 1], 'thread': [32, 2, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1__subtract_multiply_2>: {'block': [64, 1, 1], 'thread': [64, 1, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_1', 'subtract_multiply_2', 'mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1>: {'block': [1, 8, 1], 'thread': [1, 8, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'T_cast': 4}}, <Node, subtract_multiply_2>: {'block': [1, 8, 512], 'thread': [1, 8, 16], 'rstep': [], 'step': [1, 1, 2]}, <Node, mean_add_sqrt_3>: {'block': [1, 8, 512], 'thread': [1, 8, 16], 'rstep': [256], 'step': [1, 1, 2], 'vectorize': {'T_cast': 4}}, <Node, divide_multiply_add_reshape_cast_cast_4>: {'block': [8, 512], 'thread': [1, 128], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, divide_multiply_add_reshape_cast_cast_4>, Tensor(shape=[512, 128, 512], op.name=p0), 8192, 131072)

['mean_1', 'subtract_multiply_2', 'mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1>: {'block': [1, 4, 1], 'thread': [1, 4, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'T_cast': 4}}, <Node, subtract_multiply_2>: {'block': [1, 4, 512], 'thread': [1, 4, 32], 'rstep': [], 'step': [1, 1, 2]}, <Node, mean_add_sqrt_3>: {'block': [1, 4, 512], 'thread': [1, 4, 32], 'rstep': [512], 'step': [1, 1, 2], 'vectorize': {'T_cast': 4}}, <Node, divide_multiply_add_reshape_cast_cast_4>: {'block': [4, 512], 'thread': [1, 128], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, divide_multiply_add_reshape_cast_cast_4>, Tensor(shape=[512, 128, 512], op.name=p0), 4096, 131072)

['mean_1', 'subtract_multiply_2', 'mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1>: {'block': [1, 2, 1], 'thread': [1, 2, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'T_cast': 4}}, <Node, subtract_multiply_2>: {'block': [1, 2, 512], 'thread': [1, 2, 64], 'rstep': [], 'step': [1, 1, 2]}, <Node, mean_add_sqrt_3>: {'block': [1, 2, 512], 'thread': [1, 2, 64], 'rstep': [512], 'step': [1, 1, 2], 'vectorize': {'T_cast': 4}}, <Node, divide_multiply_add_reshape_cast_cast_4>: {'block': [2, 512], 'thread': [1, 128], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, divide_multiply_add_reshape_cast_cast_4>, Tensor(shape=[512, 128, 512], op.name=p0), 2048, 131072)

['mean_1', 'subtract_multiply_2', 'mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_1>: {'block': [1, 16, 1], 'thread': [1, 16, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'T_cast': 4}}, <Node, subtract_multiply_2>: {'block': [1, 16, 512], 'thread': [1, 16, 8], 'rstep': [], 'step': [1, 1, 2]}, <Node, mean_add_sqrt_3>: {'block': [1, 16, 512], 'thread': [1, 16, 8], 'rstep': [256], 'step': [1, 1, 2], 'vectorize': {'T_cast': 4}}, <Node, divide_multiply_add_reshape_cast_cast_4>: {'block': [16, 512], 'thread': [1, 128], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, divide_multiply_add_reshape_cast_cast_4>, Tensor(shape=[512, 128, 512], op.name=p0), 16384, 131072)

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [1, 32, 1], 'thread': [1, 32, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [1, 8, 1], 'thread': [1, 8, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [1, 16, 1], 'thread': [1, 16, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [1, 4, 1], 'thread': [1, 4, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [1, 64, 1], 'thread': [1, 64, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [1, 2, 1], 'thread': [1, 2, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [2, 32, 1], 'thread': [2, 32, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [1, 1, 1], 'thread': [1, 1, 1], 'rstep': [512], 'reduce_thread': [128], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [2, 16, 1], 'thread': [2, 16, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [4, 16, 1], 'thread': [4, 16, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [2, 8, 1], 'thread': [2, 8, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [4, 8, 1], 'thread': [4, 8, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [2, 4, 1], 'thread': [2, 4, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [8, 8, 1], 'thread': [8, 8, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [4, 4, 1], 'thread': [4, 4, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [8, 4, 1], 'thread': [8, 4, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [2, 2, 1], 'thread': [2, 2, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [16, 4, 1], 'thread': [16, 4, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [4, 2, 1], 'thread': [4, 2, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [8, 2, 1], 'thread': [8, 2, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [16, 2, 1], 'thread': [16, 2, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [2, 1, 1], 'thread': [2, 1, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [32, 2, 1], 'thread': [32, 2, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [4, 1, 1], 'thread': [4, 1, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [8, 1, 1], 'thread': [8, 1, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [16, 1, 1], 'thread': [16, 1, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [32, 1, 1], 'thread': [32, 1, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3__divide_multiply_add_reshape_cast_cast_4>: {'block': [64, 1, 1], 'thread': [64, 1, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['mean_add_sqrt_3', 'divide_multiply_add_reshape_cast_cast_4', 'ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_3>: {'block': [1, 1, 512], 'thread': [1, 1, 128], 'rstep': [512], 'step': [1, 1, 2], 'vectorize': {'T_cast': 4}}, <Node, divide_multiply_add_reshape_cast_cast_4>: {'block': [1, 512], 'thread': [1, 128], 'rstep': [], 'step': [1, 4]}, <Node, ladder_quant_linear_cast_5>: {'block': [1, 512], 'thread': [1, 128], 'rstep': [32], 'step': [1, 2], 'vectorize': {'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 192, in compile
    and self.grid_size == sch.grid_size
AssertionError

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [128, 128], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [64, 128], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [128, 256], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [256, 128], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [128, 64], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [32, 128], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [64, 256], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [64, 64], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [256, 64], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [128, 32], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [16, 128], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [32, 256], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [32, 64], 'thread': [8, 16], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [64, 32], 'thread': [16, 8], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [256, 32], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [128, 16], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [8, 128], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 8, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [16, 256], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [16, 64], 'thread': [8, 16], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [32, 32], 'thread': [16, 8], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [64, 16], 'thread': [16, 8], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [256, 16], 'thread': [32, 4], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [128, 8], 'thread': [16, 8], 'rstep': [128], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [4, 128], 'thread': [2, 64], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 4, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [8, 256], 'thread': [2, 64], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 8, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [8, 64], 'thread': [4, 32], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [16, 32], 'thread': [8, 16], 'rstep': [512], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  42: TVMFuncCall
  41: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  40: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  39: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  38: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  37: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  36: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  35: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  34: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  28: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  27: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  26: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [32, 16], 'thread': [16, 8], 'rstep': [512], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  42: TVMFuncCall
  41: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  40: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  39: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  38: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  37: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  36: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  35: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  34: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  28: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  27: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  26: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [64, 8], 'thread': [16, 8], 'rstep': [256], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [256, 8], 'thread': [32, 4], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [2, 128], 'thread': [2, 64], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 2, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [4, 256], 'thread': [2, 64], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 4, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [128, 4], 'thread': [32, 4], 'rstep': [128], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [4, 64], 'thread': [4, 32], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 8, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [8, 32], 'thread': [8, 16], 'rstep': [512], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  42: TVMFuncCall
  41: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  40: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  39: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  38: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  37: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  36: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  35: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  34: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  28: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  27: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  26: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [16, 16], 'thread': [16, 8], 'rstep': [512], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  42: TVMFuncCall
  41: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  40: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  39: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  38: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  37: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  36: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  35: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  34: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  28: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  27: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  26: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [32, 8], 'thread': [16, 8], 'rstep': [512], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  42: TVMFuncCall
  41: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  40: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  39: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  38: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  37: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  36: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  35: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  34: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  28: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  27: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  26: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [64, 4], 'thread': [32, 4], 'rstep': [256], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_5']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_5>: {'block': [256, 4], 'thread': [32, 4], 'rstep': [128], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 64, 64], 'thread': [1, 2, 64], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [64, 64], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 8192, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 32, 128], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [32, 128], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 8192, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 32, 64], 'thread': [1, 2, 64], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [32, 64], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 4096, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 16, 256], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [16, 256], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 8192, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 16, 128], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [16, 128], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 4096, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 16, 64], 'thread': [1, 2, 64], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [16, 64], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 2048, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 128, 64], 'thread': [1, 2, 64], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [128, 64], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 16384, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 64, 128], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [64, 128], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 16384, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 32, 256], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [32, 256], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 16384, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 8, 512], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [8, 512], 'thread': [8, 16], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 8192, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 8, 256], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [8, 256], 'thread': [8, 16], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 4096, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 8, 128], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [8, 128], 'thread': [8, 16], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 2048, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 8, 64], 'thread': [1, 2, 64], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [8, 64], 'thread': [8, 16], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 1024, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 16, 512], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [16, 512], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 16384, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 4, 512], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [4, 512], 'thread': [4, 32], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 4096, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 4, 256], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [4, 256], 'thread': [4, 32], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 2048, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 4, 128], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [4, 128], 'thread': [4, 32], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 1024, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 4, 64], 'thread': [1, 2, 64], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [4, 64], 'thread': [4, 32], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 512, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 2, 512], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [2, 512], 'thread': [2, 64], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 2048, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 2, 64], 'thread': [1, 2, 64], 'rstep': []}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [2, 64], 'thread': [2, 64], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 256, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 2, 256], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [2, 256], 'thread': [2, 64], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 1024, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 2, 128], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [2, 128], 'thread': [2, 64], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 512, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [2, 128, 64], 'thread': [2, 1, 64], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [256, 64], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 32768, 262144)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 128, 128], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [128, 128], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 32768, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 64, 256], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [64, 256], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 32768, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 32, 512], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [32, 512], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 32768, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 128, 32], 'thread': [1, 4, 32], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [128, 32], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 8192, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 64, 32], 'thread': [1, 4, 32], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [64, 32], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 4096, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 32, 32], 'thread': [1, 4, 32], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [32, 32], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 2048, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 16, 32], 'thread': [1, 4, 32], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [16, 32], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 1024, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [2, 128, 32], 'thread': [2, 2, 32], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [256, 32], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 16384, 262144)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 8, 32], 'thread': [1, 4, 32], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [8, 32], 'thread': [8, 16], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 512, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 4, 32], 'thread': [1, 4, 32], 'rstep': []}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [4, 32], 'thread': [4, 32], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 256, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 2, 32], 'thread': [1, 2, 32], 'rstep': []}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [2, 32], 'thread': [2, 32], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 128, 131072)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [4, 128, 32], 'thread': [4, 1, 32], 'rstep': [], 'step': [1, 2, 1]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [512, 32], 'thread': [16, 8], 'rstep': [], 'step': [1, 4]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, sigmoid_multiply_reshape_cast_cast_7>, Tensor(shape=[512, 128, 512], op.name=p0), 32768, 524288)

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7', 'ladder_quant_linear_cast_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 1, 512], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [1, 512], 'thread': [1, 128], 'rstep': [], 'step': [1, 4]}, <Node, ladder_quant_linear_cast_8>: {'block': [1, 512], 'thread': [1, 128], 'rstep': [32], 'step': [1, 2], 'vectorize': {'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 192, in compile
    and self.grid_size == sch.grid_size
AssertionError

['reshape_add_6', 'sigmoid_multiply_reshape_cast_cast_7', 'ladder_quant_linear_cast_8', 'reshape_add_multiply_add_9']
{'globals': {'Rasterization': <NoRasterization>}, <Node, reshape_add_6>: {'block': [1, 1, 512], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}, <Node, sigmoid_multiply_reshape_cast_cast_7>: {'block': [1, 512], 'thread': [1, 128], 'rstep': [], 'step': [1, 4]}, <Node, ladder_quant_linear_cast_8>: {'block': [1, 512], 'thread': [1, 128], 'rstep': [32], 'step': [1, 2], 'vectorize': {'B_decode': 16}}, <Node, reshape_add_multiply_add_9>: {'block': [1, 1, 512], 'thread': [1, 1, 128], 'rstep': [], 'step': [1, 1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 192, in compile
    and self.grid_size == sch.grid_size
AssertionError

['mean_add_sqrt_12', 'divide_multiply_add_reshape_cast_cast_13', 'ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, mean_add_sqrt_12>: {'block': [1, 1, 512], 'thread': [1, 1, 128], 'rstep': [512], 'step': [1, 1, 2], 'vectorize': {'T_cast': 4}}, <Node, divide_multiply_add_reshape_cast_cast_13>: {'block': [1, 512], 'thread': [1, 128], 'rstep': [], 'step': [1, 4]}, <Node, ladder_quant_linear_cast_14>: {'block': [1, 1536], 'thread': [1, 128], 'rstep': [8], 'step': [1, 2], 'vectorize': {'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 192, in compile
    and self.grid_size == sch.grid_size
AssertionError

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 128], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [64, 128], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [256, 128], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 256], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 192], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 96], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [64, 192], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [64, 96], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 64], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [256, 96], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [32, 128], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 48], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [64, 256], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [64, 64], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [256, 192], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [32, 192], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [256, 64], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [32, 96], 'thread': [8, 16], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 32], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [64, 48], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [256, 48], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [16, 128], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [32, 256], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [32, 64], 'thread': [8, 16], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 24], 'thread': [16, 8], 'rstep': [128], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [64, 384], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [16, 192], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [64, 32], 'thread': [16, 8], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [16, 96], 'thread': [4, 32], 'rstep': [128], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [256, 32], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [32, 48], 'thread': [8, 16], 'rstep': [256], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 16], 'thread': [16, 8], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [64, 24], 'thread': [16, 8], 'rstep': [256], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [256, 24], 'thread': [32, 4], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [8, 128], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 8, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [16, 256], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [16, 64], 'thread': [8, 16], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [32, 384], 'thread': [4, 32], 'rstep': [128], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [32, 32], 'thread': [16, 8], 'rstep': [256], 'step': [1, 2], 'vectorize': {'p0': 16, 'B_decode': 16}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['ladder_quant_linear_cast_14']
{'globals': {'Rasterization': <NoRasterization>}, <Node, ladder_quant_linear_cast_14>: {'block': [128, 12], 'thread': [32, 4], 'rstep': [128], 'step': [2, 1], 'vectorize': {'p0': 16, 'B_decode': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/root/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/root/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/root/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/root/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/root/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  46: TVMFuncCall
  45: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}>(tvm::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#6}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)
  44: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  43: tvm::codegen::Build(tvm::IRModule, tvm::Target)
  42: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)
  41: tvm::codegen::BuildCUDA(tvm::IRModule, tvm::Target)
  40: tvm::codegen::CodeGenC::AddFunction(tvm::tir::PrimFunc const&)
  39: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  37: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  36: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  34: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  32: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  28: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  27: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  25: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::ForNode const*)
  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::ForNode const*)
  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::SeqStmtNode const*)
  21: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  20: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  19: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: tvm::codegen::CodeGenCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)
  17: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)
  14: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  13: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  12: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  11: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  10: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  9: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  8: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  7: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  6: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  5: tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::ostream&)
  4: tvm::codegen::PrintBinaryIntrinsic(tvm::tir::CallNode const*, char const*, std::ostream&, tvm::codegen::CodeGenC*)
  3: tvm::codegen::CodeGenCUDA::PrintVecBinaryOp(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::DataType, tvm::PrimExpr, tvm::PrimExpr, std::ostream&)
  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)
  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)
  0: tvm::codegen::CodeGenCUDA::VisitExpr_(tvm::tir::BroadcastNode const*, std::ostream&)
  File "/root/Ladder/3rdparty/tvm/src/target/source/codegen_cuda.cc", line 1226
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (p) is false: 

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [1, 2, 1], 'thread': [1, 2, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [2, 1, 1], 'thread': [2, 1, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [1, 1, 1], 'thread': [1, 1, 1], 'rstep': [512], 'reduce_thread': [128], 'vectorize': {'input0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [1, 64, 1], 'thread': [1, 64, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [2, 32, 1], 'thread': [2, 32, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [4, 16, 1], 'thread': [4, 16, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [8, 8, 1], 'thread': [8, 8, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [16, 4, 1], 'thread': [16, 4, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [32, 2, 1], 'thread': [32, 2, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [64, 1, 1], 'thread': [64, 1, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [1, 32, 1], 'thread': [1, 32, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [2, 16, 1], 'thread': [2, 16, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [4, 8, 1], 'thread': [4, 8, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [8, 4, 1], 'thread': [8, 4, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [16, 2, 1], 'thread': [16, 2, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [32, 1, 1], 'thread': [32, 1, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [1, 16, 1], 'thread': [1, 16, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [2, 8, 1], 'thread': [2, 8, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [4, 4, 1], 'thread': [4, 4, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [8, 2, 1], 'thread': [8, 2, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [16, 1, 1], 'thread': [16, 1, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [1, 8, 1], 'thread': [1, 8, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [2, 4, 1], 'thread': [2, 4, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [4, 2, 1], 'thread': [4, 2, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [8, 1, 1], 'thread': [8, 1, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [1, 4, 1], 'thread': [1, 4, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [2, 2, 1], 'thread': [2, 2, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['max_21', 'subtract_exp_22']
{'globals': {'Rasterization': <NoRasterization>}, <Node, max_21__subtract_exp_22>: {'block': [4, 1, 1], 'thread': [4, 1, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [1, 2, 1], 'thread': [1, 2, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [2, 1, 1], 'thread': [2, 1, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [1, 1, 1], 'thread': [1, 1, 1], 'rstep': [512], 'reduce_thread': [128], 'vectorize': {'input0': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [1, 64, 1], 'thread': [1, 64, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [2, 32, 1], 'thread': [2, 32, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [4, 16, 1], 'thread': [4, 16, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [8, 8, 1], 'thread': [8, 8, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [16, 4, 1], 'thread': [16, 4, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [32, 2, 1], 'thread': [32, 2, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [64, 1, 1], 'thread': [64, 1, 1], 'rstep': [128], 'reduce_thread': [2], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [1, 32, 1], 'thread': [1, 32, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [2, 16, 1], 'thread': [2, 16, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [4, 8, 1], 'thread': [4, 8, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [8, 4, 1], 'thread': [8, 4, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [16, 2, 1], 'thread': [16, 2, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [32, 1, 1], 'thread': [32, 1, 1], 'rstep': [256], 'reduce_thread': [4], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [1, 16, 1], 'thread': [1, 16, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [2, 8, 1], 'thread': [2, 8, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [4, 4, 1], 'thread': [4, 4, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [8, 2, 1], 'thread': [8, 2, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [16, 1, 1], 'thread': [16, 1, 1], 'rstep': [512], 'reduce_thread': [8], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [1, 8, 1], 'thread': [1, 8, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [2, 4, 1], 'thread': [2, 4, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [4, 2, 1], 'thread': [4, 2, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [8, 1, 1], 'thread': [8, 1, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [1, 4, 1], 'thread': [1, 4, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [2, 2, 1], 'thread': [2, 2, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['sum_23', 'divide_24']
{'globals': {'Rasterization': <NoRasterization>}, <Node, sum_23__divide_24>: {'block': [4, 1, 1], 'thread': [4, 1, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'input0': 8}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 128, 64], 'warp': [1, 64, 32], 'wmma': [16, 8, 16], 'use_cutlass': True, 'rstep': [32], 'block_order': ((floormod(block_idx, 8)*512) + floordiv(block_idx, 1024)), 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}, <Node, transpose_reshape_27>: {'block': [16, 512], 'thread': [16, 8], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 18432, 147456)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 64, 64], 'warp': [1, 32, 32], 'wmma': [16, 8, 16], 'use_cutlass': True, 'rstep': [32], 'block_order': ((floormod(block_idx, 16)*512) + floordiv(block_idx, 1024)), 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}, <Node, transpose_reshape_27>: {'block': [8, 512], 'thread': [8, 16], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 9216, 147456)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 256, 64], 'warp': [1, 128, 32], 'wmma': [16, 8, 16], 'use_cutlass': True, 'rstep': [32], 'block_order': ((floormod(block_idx, 4)*512) + floordiv(block_idx, 1024)), 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}, <Node, transpose_reshape_27>: {'block': [32, 512], 'thread': [16, 8], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 36864, 147456)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 32, 64], 'warp': [1, 16, 32], 'wmma': [16, 8, 16], 'use_cutlass': True, 'rstep': [32], 'block_order': ((floormod(block_idx, 32)*512) + floordiv(block_idx, 1024)), 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}, <Node, transpose_reshape_27>: {'block': [4, 512], 'thread': [4, 32], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 4608, 147456)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 16, 64], 'warp': [1, 16, 16], 'wmma': [16, 8, 16], 'use_cutlass': True, 'rstep': [32], 'block_order': ((floormod(block_idx, 64)*512) + floordiv(block_idx, 1024)), 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}, <Node, transpose_reshape_27>: {'block': [2, 512], 'thread': [2, 64], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 2304, 147456)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 128, 64], 'thread': [1, 16, 8], 'rstep': [64], 'block_order': ((floormod(block_idx, 8)*512) + floordiv(block_idx, 1024)), 'step': [1, 1, 2], 'vectorize': {'p0': 8, 'p1': 8}}, <Node, transpose_reshape_27>: {'block': [16, 512], 'thread': [16, 8], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 16384, 131072)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 64, 64], 'thread': [1, 16, 8], 'rstep': [64], 'block_order': ((floormod(block_idx, 16)*512) + floordiv(block_idx, 1024)), 'step': [1, 1, 2], 'vectorize': {'p0': 8, 'p1': 8}}, <Node, transpose_reshape_27>: {'block': [8, 512], 'thread': [8, 16], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 8192, 131072)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 256, 64], 'thread': [1, 32, 4], 'rstep': [64], 'block_order': ((floormod(block_idx, 4)*512) + floordiv(block_idx, 1024)), 'step': [1, 1, 2], 'vectorize': {'p0': 8, 'p1': 8}}, <Node, transpose_reshape_27>: {'block': [32, 512], 'thread': [16, 8], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 32768, 131072)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 32, 64], 'thread': [1, 8, 16], 'rstep': [128], 'block_order': ((floormod(block_idx, 32)*512) + floordiv(block_idx, 1024)), 'step': [1, 1, 2], 'vectorize': {'p0': 8, 'p1': 8}}, <Node, transpose_reshape_27>: {'block': [4, 512], 'thread': [4, 32], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 4096, 131072)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 16, 64], 'thread': [1, 8, 16], 'rstep': [128], 'block_order': ((floormod(block_idx, 64)*512) + floordiv(block_idx, 1024)), 'step': [1, 1, 2], 'vectorize': {'p0': 8, 'p1': 8}}, <Node, transpose_reshape_27>: {'block': [2, 512], 'thread': [2, 64], 'rstep': [], 'step': [1, 2]}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 2048, 131072)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 1, 32], 'thread': [1, 1, 32], 'rstep': [256], 'block_order': (((floordiv(floormod(block_idx, 2048), 2)*1024) + (floordiv(block_idx, 2048)*2)) + floormod(block_idx, 2)), 'vectorize': {'p0': 8, 'p1': 8}}, <Node, transpose_reshape_27>: {'block': [1, 32], 'thread': [1, 32], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 64, 128)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 1, 16], 'thread': [1, 1, 16], 'rstep': [512], 'block_order': (((floordiv(floormod(block_idx, 4096), 4)*2048) + (floordiv(block_idx, 4096)*4)) + floormod(block_idx, 4)), 'vectorize': {'p0': 8, 'p1': 8}}, <Node, transpose_reshape_27>: {'block': [1, 16], 'thread': [1, 16], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 32, 128)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 1, 8], 'thread': [1, 1, 8], 'rstep': [512], 'block_order': (((floordiv(floormod(block_idx, 8192), 8)*4096) + (floordiv(block_idx, 8192)*8)) + floormod(block_idx, 8)), 'vectorize': {'p0': 8, 'p1': 8}}, <Node, transpose_reshape_27>: {'block': [1, 8], 'thread': [1, 8], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 32, 128)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 1, 4], 'thread': [1, 1, 4], 'rstep': [512], 'block_order': (((floordiv(floormod(block_idx, 16384), 16)*8192) + (floordiv(block_idx, 16384)*16)) + floormod(block_idx, 16)), 'vectorize': {'p0': 8, 'p1': 4}}, <Node, transpose_reshape_27>: {'block': [1, 4], 'thread': [1, 4], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 32, 128)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26>: {'block': [1, 1, 2], 'thread': [1, 1, 2], 'rstep': [512], 'block_order': (((floordiv(floormod(block_idx, 32768), 32)*16384) + (floordiv(block_idx, 32768)*32)) + floormod(block_idx, 32)), 'vectorize': {'p0': 8, 'p1': 2}}, <Node, transpose_reshape_27>: {'block': [1, 2], 'thread': [1, 2], 'rstep': []}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/root/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, transpose_reshape_27>, Tensor(shape=[1024, 512, 64], op.name=p0), 32, 128)

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 16, 64], 'warp': [4, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 8, 64], 'warp': [2, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [8, 16, 64], 'warp': [8, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [8, 8, 64], 'warp': [4, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 32, 64], 'warp': [4, 16, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [8, 16, 32], 'warp': [4, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [8, 8, 32], 'warp': [2, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 32, 64], 'warp': [2, 16, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 16, 64], 'warp': [2, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 8, 64], 'warp': [1, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 32, 32], 'warp': [4, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 64, 64], 'warp': [2, 32, 32], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 16, 32], 'warp': [2, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 64, 64], 'warp': [4, 32, 32], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [8, 32, 64], 'warp': [8, 16, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [8, 32, 32], 'warp': [8, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 8, 32], 'warp': [1, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [8, 16, 16], 'warp': [2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 24>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 64, 32], 'warp': [4, 32, 16], 'wmma': [32, 8, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 128, 64], 'warp': [2, 64, 32], 'wmma': [32, 8, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [16, 16, 16], 'warp': [4, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 24>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [8, 32, 16], 'warp': [4, 32, 8], 'wmma': [32, 8, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 24>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [1, 8, 64], 'warp': [1, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 72>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [16, 8, 32], 'warp': [4, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 64, 32], 'warp': [2, 32, 16], 'wmma': [32, 8, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 32, 32], 'warp': [2, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 16, 32], 'warp': [1, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 8, 32], 'warp': [1, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 32, 16], 'warp': [2, 32, 8], 'wmma': [32, 8, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 24>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 16, 16], 'warp': [1, 16, 16], 'wmma': [16, 16, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 24>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [2, 128, 32], 'warp': [2, 64, 16], 'wmma': [32, 8, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [4, 64, 16], 'warp': [4, 32, 8], 'wmma': [32, 8, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 24>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [8, 32, 8], 'warp': [2, 32, 8], 'wmma': [32, 8, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 16>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['welder_matmul_26', 'transpose_reshape_27']
{'globals': {'Rasterization': <NoRasterization>}, <Node, welder_matmul_26__transpose_reshape_27>: {'block': [1, 8, 32], 'warp': [1, 8, 32], 'wmma': [8, 32, 16], 'use_cutlass': False, 'rstep': [32], 'use_tc': '80', 'strides': {2: <Stride, 1, 40>}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [1, 8, 1], 'thread': [1, 8, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [2, 4, 1], 'thread': [2, 4, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [4, 2, 1], 'thread': [4, 2, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [8, 1, 1], 'thread': [8, 1, 1], 'rstep': [512], 'reduce_thread': [16], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [1, 4, 1], 'thread': [1, 4, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [2, 2, 1], 'thread': [2, 2, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [4, 1, 1], 'thread': [4, 1, 1], 'rstep': [512], 'reduce_thread': [32], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [1, 2, 1], 'thread': [1, 2, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [2, 1, 1], 'thread': [2, 1, 1], 'rstep': [512], 'reduce_thread': [64], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [1, 1, 1], 'thread': [1, 1, 1], 'rstep': [512], 'reduce_thread': [128], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [1, 32, 1], 'thread': [1, 32, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [2, 16, 1], 'thread': [2, 16, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [4, 8, 1], 'thread': [4, 8, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [8, 4, 1], 'thread': [8, 4, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [16, 2, 1], 'thread': [16, 2, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [32, 1, 1], 'thread': [32, 1, 1], 'rstep': [128], 'reduce_thread': [4], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [1, 16, 1], 'thread': [1, 16, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [2, 8, 1], 'thread': [2, 8, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [4, 4, 1], 'thread': [4, 4, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [8, 2, 1], 'thread': [8, 2, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [16, 1, 1], 'thread': [16, 1, 1], 'rstep': [256], 'reduce_thread': [8], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [1, 64, 1], 'thread': [1, 64, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [2, 32, 1], 'thread': [2, 32, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [4, 16, 1], 'thread': [4, 16, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [8, 8, 1], 'thread': [8, 8, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [16, 4, 1], 'thread': [16, 4, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [32, 2, 1], 'thread': [32, 2, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

['transpose_mean_30', 'subtract_multiply_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, transpose_mean_30__subtract_multiply_31>: {'block': [64, 1, 1], 'thread': [64, 1, 1], 'rstep': [64], 'reduce_thread': [2], 'vectorize': {'mediate1': 4}}}
Traceback (most recent call last):
  File "/root/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/root/Ladder/python/ladder/engine/multiproc_tunner.py", line 37, in call_build
    cpresult.code,
AttributeError: 'NoneType' object has no attribute 'code'

