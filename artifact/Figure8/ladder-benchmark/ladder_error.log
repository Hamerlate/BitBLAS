['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 4, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 3], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 4, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 4, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 4, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 7, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 7, 4, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 2, 28, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 2, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 28, 2, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 28, 2, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 2, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 2, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 14, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 14, 2, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 7, 4, 58], 'thread': [1, 1, 2, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 7, 4, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 4, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 4, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 2, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 2, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 7, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 7, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 14, 2, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 14, 2, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 2, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 2, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 7, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 7, 2, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 2, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 2, 4, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 4, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 4, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [64, 1, 2, 58], 'thread': [64, 1, 1, 2], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [64, 1, 2, 58], 'thread': [64, 1, 1, 2], 'rstep': [1, 1, 2], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [64, 2, 1, 58], 'thread': [64, 1, 1, 2], 'rstep': [1, 1], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [64, 2, 1, 58], 'thread': [64, 1, 1, 2], 'rstep': [1, 1, 2], 'step': [1, 2, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 1, 28, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 1, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 28, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 28, 1, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 1, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 1, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [4, 14, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [4, 14, 1, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [8, 2, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [8, 2, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [1, 28, 1, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [1, 28, 1, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [8, 1, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [8, 1, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [8, 7, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [8, 7, 1, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 1, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 1, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_6', 'nn_conv2d_multiply_add_nn_relu_7']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_6>: {'block': [2, 14, 1, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_7>: {'block': [2, 14, 1, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 14, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 28, 29], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 24]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 7, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 7, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 28, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 14, 29], 'thread': [1, 7, 14, 1], 'rstep': [1, 1, 24], 'vectorize': {'mediate0': 8}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 7, 29], 'thread': [1, 14, 7, 1], 'rstep': [1, 1, 24], 'vectorize': {'mediate0': 8}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 4, 28, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 4, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 24], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 24], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 4, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 4, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 28, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 14, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 28, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 7, 28, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 14, 14, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 28, 7, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 2, 1, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 4, 14, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 4, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 2, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 2, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 24], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 4, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 2, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [1, 28, 2, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_4', 'concatenate_layout_transform_reshape_transpose_reshape_8']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_4__concatenate_layout_transform_reshape_transpose_reshape_8>: {'block': [2, 14, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 24], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 22752, 29232)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 38976)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [4, 2, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [4, 2, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 32480)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [8, 1, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [8, 1, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 45472, 68208)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 45472, 48720)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 12992)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 22752, 34104)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 22752, 27608)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 32480)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [8, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [8, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [16, 1, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [16, 1, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 25984, 27608)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [4, 4, 28, 58], 'thread': [4, 4, 4, 2], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [4, 4, 28, 58], 'thread': [4, 4, 4, 2], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 51968, 64960)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [8, 2, 28, 58], 'thread': [8, 2, 4, 2], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [8, 2, 28, 58], 'thread': [8, 2, 4, 2], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 51968, 64960)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 17052)

['strided_slice_layout_transform_9', 'nn_conv2d_multiply_add_nn_relu_10']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_9>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_10>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_10>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 12180)

['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [3, 3], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_12>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 12992)

['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_12>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 12180)

['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [8, 4, 4, 58], 'thread': [8, 4, 2, 2], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [8, 4, 4, 58], 'thread': [8, 4, 2, 2], 'rstep': [1, 1, 2], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_12>, Tensor(shape=[128, 28, 28, 58], op.name=p0), 11392, 17052)

['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 28, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 28, 7, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 4, 28, 58], 'thread': [1, 1, 2, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 4, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 28, 4, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 28, 4, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 14, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 4, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 4, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 14, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 14, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [16, 2, 4, 58], 'thread': [16, 2, 2, 2], 'rstep': [1, 3], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [16, 2, 4, 58], 'thread': [16, 2, 2, 2], 'rstep': [1, 1, 2], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [16, 4, 2, 58], 'thread': [16, 4, 1, 2], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [16, 4, 2, 58], 'thread': [16, 4, 1, 2], 'rstep': [1, 1, 2], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 4, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 4, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 7, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 7, 4, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 4, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 4, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 7, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 7, 4, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [1, 28, 2, 58], 'thread': [1, 2, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [1, 28, 2, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 2, 28, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 2, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 28, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 28, 2, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 2, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 2, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 14, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 14, 2, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 4, 28, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [2, 28, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [2, 28, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 2, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 14, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 14, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 2, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 2, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 7, 2, 58], 'thread': [2, 1, 1, 58], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 7, 2, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 4, 14, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_11', 'nn_conv2d_multiply_add_nn_relu_12']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_11>: {'block': [4, 14, 4, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_12>: {'block': [4, 14, 4, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 2], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 4, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 7, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 28, 29], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 2, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 14, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 4, 28, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 4, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 14, 29], 'thread': [1, 7, 14, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 2, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 4, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 4, 28, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 7, 29], 'thread': [1, 14, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 7, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 28, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 4, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 28, 4, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 14, 14, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [4, 2, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 28, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 14, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 1, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [1, 2, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 7, 14, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_12', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_12__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_13>: {'block': [2, 28, 4, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 7, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 4, 28, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 14, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 14, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 7, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 4, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 2, 28, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 14, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  14: TVMFuncCall
  13: _ZN3tvm7runtime13PackedFuncObj
  12: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  11: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  10: tvm::ScheduleToModule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply)
  9: tvm::te::InferBound(tvm::te::Schedule const&)
  8: tvm::arith::Analyzer::Simplify(tvm::PrimExpr const&, int)
  7: tvm::arith::CanonicalSimplifier::operator()(tvm::PrimExpr const&)
  6: non-virtual thunk to tvm::arith::CanonicalSimplifier::Impl::VisitExpr(tvm::PrimExpr const&)
  5: tvm::arith::SumExprNode::Normalize() const
  4: tvm::arith::SumExprNode::Normalize_(tvm::runtime::DataType, std::vector<tvm::arith::SplitExpr, std::allocator<tvm::arith::SplitExpr> > const&, long)
  3: tvm::arith::SplitExprNode::NormalizeWithScale(long) const
  2: tvm::PrimExpr tvm::tir::make_const<long, void>(tvm::runtime::DataType, long, tvm::Span)
  1: tvm::PrimExpr tvm::tir::MakeConstScalar<long>(tvm::runtime::DataType, long, tvm::Span)
  0: tvm::IntImm::IntImm(tvm::runtime::DataType, long, tvm::Span)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/src/ir/expr.cc", line 93
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value < 1LL << (dtype.bits() - 1) (2284513280 vs. 2147483648) : ValueError: Literal value 2284513280 exceeds maximum of int32

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 4, 28, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 4, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 2, 28, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 4, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 4, 28, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 7, 28, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 14, 58], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 4, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 7, 28, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 14, 4, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 28, 4, 29], 'thread': [1, 4, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  14: TVMFuncCall
  13: _ZN3tvm7runtime13PackedFuncObj
  12: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  11: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  10: tvm::ScheduleToModule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply)
  9: tvm::te::InferBound(tvm::te::Schedule const&)
  8: tvm::arith::Analyzer::Simplify(tvm::PrimExpr const&, int)
  7: tvm::arith::CanonicalSimplifier::operator()(tvm::PrimExpr const&)
  6: non-virtual thunk to tvm::arith::CanonicalSimplifier::Impl::VisitExpr(tvm::PrimExpr const&)
  5: tvm::arith::SumExprNode::Normalize() const
  4: tvm::arith::SumExprNode::Normalize_(tvm::runtime::DataType, std::vector<tvm::arith::SplitExpr, std::allocator<tvm::arith::SplitExpr> > const&, long)
  3: tvm::arith::SplitExprNode::NormalizeWithScale(long) const
  2: tvm::PrimExpr tvm::tir::make_const<long, void>(tvm::runtime::DataType, long, tvm::Span)
  1: tvm::PrimExpr tvm::tir::MakeConstScalar<long>(tvm::runtime::DataType, long, tvm::Span)
  0: tvm::IntImm::IntImm(tvm::runtime::DataType, long, tvm::Span)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/src/ir/expr.cc", line 93
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value < 1LL << (dtype.bits() - 1) (2282434560 vs. 2147483648) : ValueError: Literal value 2282434560 exceeds maximum of int32

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 14, 14, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  16: TVMFuncCall
  15: _ZN3tvm7runtime13PackedFuncObj
  14: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  13: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  12: tvm::ScheduleToModule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply)
  11: tvm::te::InferBound(tvm::te::Schedule const&)
  10: tvm::te::PassDownDomain(tvm::te::Stage const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*, tvm::arith::Analyzer*, bool)
  9: tvm::te::PassDownDomain(tvm::te::Stage const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*, tvm::arith::Analyzer*, bool)::{lambda(tvm::PrimExpr const&, tvm::PrimExpr const&)#1}::operator()(tvm::PrimExpr const&, tvm::PrimExpr const&) const [clone .isra.0]
  8: tvm::arith::Analyzer::Simplify(tvm::PrimExpr const&, int)
  7: tvm::arith::CanonicalSimplifier::operator()(tvm::PrimExpr const&)
  6: non-virtual thunk to tvm::arith::CanonicalSimplifier::Impl::VisitExpr(tvm::PrimExpr const&)
  5: tvm::arith::SumExprNode::Normalize() const
  4: tvm::arith::SumExprNode::Normalize_(tvm::runtime::DataType, std::vector<tvm::arith::SplitExpr, std::allocator<tvm::arith::SplitExpr> > const&, long)
  3: tvm::arith::SplitExprNode::NormalizeWithScale(long) const
  2: tvm::PrimExpr tvm::tir::make_const<long, void>(tvm::runtime::DataType, long, tvm::Span)
  1: tvm::PrimExpr tvm::tir::MakeConstScalar<long>(tvm::runtime::DataType, long, tvm::Span)
  0: tvm::IntImm::IntImm(tvm::runtime::DataType, long, tvm::Span)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/src/ir/expr.cc", line 93
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value < 1LL << (dtype.bits() - 1) (16562721280 vs. 2147483648) : ValueError: Literal value 16562721280 exceeds maximum of int32

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [4, 2, 28, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 28, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [4, 4, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 14, 4, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 1, 28, 58], 'thread': [1, 1, 4, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [1, 2, 28, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  48: TVMFuncCall
  47: _ZN3tvm7runtime13PackedFuncObj
  46: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  45: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  44: tvm::LowerWithPassList(tvm::IRModule, tvm::runtime::Array<tvm::transform::Pass, void>)
  43: tvm::transform::Pass::operator()(tvm::IRModule) const
  42: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  41: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  40: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  39: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  38: _ZN3tvm7runtime13PackedFuncObj9ExtractorINS0_16PackedFuncSubObjIZNS0_15TypedPackedFuncIFNS_3tir8PrimFuncES6_NS_8IRModuleENS_9transform11PassContextEEE17AssignTypedLambdaIZNS5_9transform10UnrollLoopEvEUlS6_S7_S9_E_EEvT_EUlRKNS0_7TVMArgsEPNS0_11TVMRetValueEE_EEE4CallEPKS1_SG_SK_
  37: tvm::tir::UnrollLoop(tvm::tir::Stmt, tvm::tir::UnrollLoopConfig)
  36: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  35: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  34: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  33: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  31: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  30: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  28: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  27: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  25: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  24: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  22: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  21: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  20: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  19: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AllocateNode const*)
  18: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  17: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  16: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::AttrStmtNode const*)
  15: tvm::tir::StmtMutator::VisitStmt_(tvm::tir::AttrStmtNode const*)
  14: tvm::tir::StmtMutator::VisitStmt(tvm::tir::Stmt const&)
  13: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  12: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  11: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  10: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  9: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  8: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  7: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime9Ob
  6: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)
  5: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  4: tvm::tir::StmtMutator::VisitSeqStmt_(tvm::tir::SeqStmtNode const*, bool, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)::{lambda(tvm::tir::SeqStmtNode const*)#1}::operator()(tvm::tir::SeqStmtNode const*) const [clone .isra.0]
  3: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>, tvm::tir::Stmt>(tvm::runtime::ObjectPtr<tvm::runtime::Object>, std::function<tvm::tir::Stmt (tvm::tir::Stmt const&)>)
  2: std::_Function_handler<tvm::tir::Stmt (tvm::tir::Stmt const&), tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::SeqStmtNode const*)::{lambda(tvm::tir::Stmt const&)#1}>::_M_invoke(std::_Any_data const&, tvm::tir::Stmt const&)
  1: _ZZN3tvm3tir11StmtFunctorIFNS0_4StmtERKS2_EE10InitVTableEvENUlRKNS_7runtime
  0: tvm::tir::LoopUnroller::VisitStmt_(tvm::tir::ForNode const*)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/src/tir/transforms/unroll_loop.cc", line 110
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value >= 0 (-1 vs. 0) : Cannot unroll non-constant loop

['nn_conv2d_multiply_add_nn_relu_22', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_22__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_layout_transform_23>: {'block': [2, 28, 4, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 109, in compile
    return self._compile_single_node(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 261, in _compile_single_node
    code, _, _ = tvm_build(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/tvm_build.py", line 183, in tvm_build
    src = sch.build(target)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/schedule/te_base.py", line 64, in build
    mod = tvm.build(self.sche, self.args, target=target)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 227, in build
    input_mod = lower(inputs, args, name=name, binds=binds)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/driver/build_module.py", line 134, in lower
    return ffi.lower_schedule(inp, args, name, binds, simple_mode)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 237, in __call__
    raise get_last_ffi_error()
tvm._ffi.base.TVMError: Traceback (most recent call last):
  14: TVMFuncCall
  13: _ZN3tvm7runtime13PackedFuncObj
  12: tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)>::AssignTypedLambda<tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}>(tvm::{lambda(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, tvm::runtime::String const&, tvm::runtime::Map<tvm::te::Tensor, tvm::tir::Buffer, void, void> const&, bool)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  11: tvm::LowerSchedule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply, bool)
  10: tvm::ScheduleToModule(tvm::te::Schedule, tvm::runtime::Array<tvm::runtime::ObjectRef, void> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_map<tvm::te::Tensor, tvm::tir::Buffer, std::hash<tvm::te::Tensor>, std::equal_to<tvm::te::Tensor>, std::allocator<std::pair<tvm::te::Tensor const, tvm::tir::Buffer> > > const&, tvm::GlobalVarSupply)
  9: tvm::te::InferBound(tvm::te::Schedule const&)
  8: tvm::arith::Analyzer::Simplify(tvm::PrimExpr const&, int)
  7: tvm::arith::CanonicalSimplifier::operator()(tvm::PrimExpr const&)
  6: non-virtual thunk to tvm::arith::CanonicalSimplifier::Impl::VisitExpr(tvm::PrimExpr const&)
  5: tvm::arith::SumExprNode::Normalize() const
  4: tvm::arith::SumExprNode::Normalize_(tvm::runtime::DataType, std::vector<tvm::arith::SplitExpr, std::allocator<tvm::arith::SplitExpr> > const&, long)
  3: tvm::arith::SplitExprNode::NormalizeWithScale(long) const
  2: tvm::PrimExpr tvm::tir::make_const<long, void>(tvm::runtime::DataType, long, tvm::Span)
  1: tvm::PrimExpr tvm::tir::MakeConstScalar<long>(tvm::runtime::DataType, long, tvm::Span)
  0: tvm::IntImm::IntImm(tvm::runtime::DataType, long, tvm::Span)
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/src/ir/expr.cc", line 93
TVMError: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------

  Check failed: value < 1LL << (dtype.bits() - 1) (2282434560 vs. 2147483648) : ValueError: Literal value 2282434560 exceeds maximum of int32

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [32, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [32, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [32, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 2, 1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [32, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 2, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [64, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [64, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [16, 2, 1, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [16, 2, 1, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [32, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [32, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 2, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 7, 2, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [8, 2, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [8, 2, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [8, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [8, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [8, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [8, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 1, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 7, 1, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [16, 2, 2, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [16, 2, 2, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_28>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 11392, 12992)

['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [64, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [64, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 29], 'step': [1, 1, 2, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [64, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [64, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 29], 'step': [1, 2, 1, 1]}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [128, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [128, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 2, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 2, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [2, 14, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [2, 14, 2, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [4, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [4, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_27', 'nn_conv2d_multiply_add_nn_relu_28']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_27>: {'block': [4, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_28>: {'block': [4, 7, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 14, 29], 'thread': [1, 7, 14, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 7, 29], 'thread': [1, 14, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 7, 29], 'thread': [1, 7, 1, 29], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 2, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 2, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 2, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 14, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 2, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 2, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 7, 14, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [2, 14, 7, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 7, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [4, 14, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 7, 2, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 1, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 14, 1, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 116], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_25', 'concatenate_layout_transform_reshape_transpose_reshape_29']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_25__concatenate_layout_transform_reshape_transpose_reshape_29>: {'block': [1, 2, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 22752, 29232)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 32480)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 45472, 68208)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [8, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [8, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 22752, 34104)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 11392, 12992)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [8, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [8, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 29232)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [16, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [16, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 27608)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [1, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [1, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'vectorize': {'p1': 2}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 1632, 1856)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [8, 2, 14, 116], 'thread': [8, 2, 2, 4], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [8, 2, 14, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 51968, 64960)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 45472, 56840)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 45472, 68208)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [16, 1, 14, 116], 'thread': [16, 1, 2, 4], 'rstep': []}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [16, 1, 14, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 1, 1]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 51968, 61712)

['strided_slice_layout_transform_30', 'nn_conv2d_multiply_add_nn_relu_31']
{'globals': {'Rasterization': <NoRasterization>}, <Node, strided_slice_layout_transform_30>: {'block': [4, 14, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [], 'step': [1, 1, 1, 2]}, <Node, nn_conv2d_multiply_add_nn_relu_31>: {'block': [4, 14, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_31>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 25984, 32480)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [1, 14, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [1, 14, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 2, 2, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 2, 2, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 2, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 14, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 14, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_33>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 11392, 12992)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 7, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [32, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [32, 1, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [32, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [32, 2, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 2, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 3], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 2, 2, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_33>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [1, 14, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [1, 14, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 7, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 14, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 1, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 14, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 14, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 2, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 2, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 14, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 14, 2, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 2, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 7, 2, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [1, 14, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [1, 14, 2, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 4], 'step': [1, 1, 1, 2], 'vectorize': {'p1': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 2, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 2, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 7, 2, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 7, 2, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 3], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 1, 2, 116], 'thread': [16, 1, 2, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_33>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [16, 2, 1, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 3]}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [16, 2, 1, 116], 'thread': [16, 2, 1, 4], 'rstep': [1, 1, 29]}}
Traceback (most recent call last):
  File "/home/t-leiwang/ladder_workspace/Ladder/3rdparty/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/engine/multiproc_tunner.py", line 33, in call_build
    cpresult = cgen.compile(
  File "/home/t-leiwang/ladder_workspace/Ladder/python/ladder/code_generator.py", line 199, in compile
    raise Exception(
Exception: ('Shared memory mismatched', <Node, nn_conv2d_multiply_add_nn_relu_33>, Tensor(shape=[128, 14, 14, 116], op.name=p0), 7424, 8352)

['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 1, 14, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 14, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 14, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [2, 14, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [3, 3], 'step': [1, 2, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [2, 14, 1, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [32, 2, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [1, 1, 2, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [32, 2, 2, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [1, 1, 2, 1], 'vectorize': {'pad_temp': 4}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [64, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 2}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [64, 1, 1, 116], 'thread': [32, 1, 1, 4], 'rstep': [1, 1, 4], 'step': [2, 1, 1, 1], 'vectorize': {'pad_temp': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [4, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [4, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'pad_temp': 2, 'p1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 1, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 3], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 1, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_32', 'nn_conv2d_multiply_add_nn_relu_33']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_32>: {'block': [8, 7, 1, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1], 'step': [2, 1, 1, 1], 'vectorize': {'PaddedInput': 4}}, <Node, nn_conv2d_multiply_add_nn_relu_33>: {'block': [8, 7, 1, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 29], 'step': [1, 1, 1, 2]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 14, 58], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 14, 58], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 14, 29], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 14, 29], 'thread': [1, 7, 14, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 2, 14, 116], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 7, 116], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 7, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 7, 58], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 7, 116], 'thread': [1, 1, 1, 116], 'rstep': [1, 1, 58], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 2, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 2, 14, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 7, 7, 58], 'thread': [1, 7, 7, 2], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 14, 29], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 14, 7, 29], 'thread': [1, 14, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 7, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 2, 14, 58], 'thread': [1, 2, 2, 29], 'rstep': [1, 1, 116], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 4, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 14, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 2, 1], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 7, 7, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 7, 58], 'thread': [2, 1, 1, 58], 'rstep': [1, 1, 58]}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 2, 14, 58], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 1, 14, 116], 'thread': [1, 1, 2, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 14, 7, 29], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 1, 14, 116], 'thread': [2, 1, 2, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [1, 2, 7, 116], 'thread': [1, 2, 1, 58], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 7, 7, 29], 'thread': [2, 7, 7, 1], 'rstep': [1, 1, 58], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [2, 2, 7, 116], 'thread': [2, 2, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 7, 7, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [8, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [4, 2, 14, 58], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [8, 1, 14, 116], 'thread': [4, 1, 1, 29], 'rstep': [1, 1, 58], 'step': [1, 1, 1, 2], 'vectorize': {'mediate0': 2, 'input1': 2}}}
Compiler timeout.
['nn_conv2d_multiply_add_nn_relu_33', 'strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34']
{'globals': {'Rasterization': <NoRasterization>}, <Node, nn_conv2d_multiply_add_nn_relu_33__strided_slice_layout_transform_concatenate_reshape_transpose_reshape_34>: {'block': [8, 2, 14, 116], 'thread': [8, 2, 2, 4], 'rstep': [1, 1, 58]}}
Compiler timeout.
